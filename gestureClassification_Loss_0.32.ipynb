{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled70.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDLdxJur7321jpmQQrbvrN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingun0112/GestureClassification/blob/main/gestureClassification_Loss_0.32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pvV8f-JxAfM",
        "outputId": "22b4b4b2-2239-4e36-d90e-66ba8d74d55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/hand_gesture_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeQUmzBL4Nwf",
        "outputId": "3e41ca95-2c2e-42a8-cb01-20adce3b506b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/hand_gesture_data.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jVn-43-R4No1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "path = '/content/'\n",
        "\n",
        "train = pd.read_csv(path + 'train.csv')\n",
        "test = pd.read_csv(path + 'test.csv')\n",
        "sample_submission = pd.read_csv(path + 'sample_submission.csv')\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "4wMKuD6n37p3",
        "outputId": "eedf6f72-3812-48e8-f156-867062c7e3bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e3f7f4fe-9635-4461-80f3-2715ad77af5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sensor_1</th>\n",
              "      <th>sensor_2</th>\n",
              "      <th>sensor_3</th>\n",
              "      <th>sensor_4</th>\n",
              "      <th>sensor_5</th>\n",
              "      <th>sensor_6</th>\n",
              "      <th>sensor_7</th>\n",
              "      <th>sensor_8</th>\n",
              "      <th>sensor_9</th>\n",
              "      <th>...</th>\n",
              "      <th>sensor_24</th>\n",
              "      <th>sensor_25</th>\n",
              "      <th>sensor_26</th>\n",
              "      <th>sensor_27</th>\n",
              "      <th>sensor_28</th>\n",
              "      <th>sensor_29</th>\n",
              "      <th>sensor_30</th>\n",
              "      <th>sensor_31</th>\n",
              "      <th>sensor_32</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-6.149463</td>\n",
              "      <td>-0.929714</td>\n",
              "      <td>9.058368</td>\n",
              "      <td>-7.017854</td>\n",
              "      <td>-2.958471</td>\n",
              "      <td>0.179233</td>\n",
              "      <td>-0.956591</td>\n",
              "      <td>-0.972401</td>\n",
              "      <td>5.956213</td>\n",
              "      <td>...</td>\n",
              "      <td>-7.026436</td>\n",
              "      <td>-6.006282</td>\n",
              "      <td>-6.005836</td>\n",
              "      <td>7.043084</td>\n",
              "      <td>21.884650</td>\n",
              "      <td>-3.064152</td>\n",
              "      <td>-5.247552</td>\n",
              "      <td>-6.026107</td>\n",
              "      <td>-11.990822</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-2.238836</td>\n",
              "      <td>-1.003511</td>\n",
              "      <td>5.098079</td>\n",
              "      <td>-10.880357</td>\n",
              "      <td>-0.804562</td>\n",
              "      <td>-2.992123</td>\n",
              "      <td>26.972724</td>\n",
              "      <td>-8.900861</td>\n",
              "      <td>-5.968298</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.996714</td>\n",
              "      <td>-7.933806</td>\n",
              "      <td>-3.136773</td>\n",
              "      <td>8.774211</td>\n",
              "      <td>10.944759</td>\n",
              "      <td>9.858186</td>\n",
              "      <td>-0.969241</td>\n",
              "      <td>-3.935553</td>\n",
              "      <td>-15.892421</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>19.087934</td>\n",
              "      <td>-2.092514</td>\n",
              "      <td>0.946750</td>\n",
              "      <td>-21.831788</td>\n",
              "      <td>9.119235</td>\n",
              "      <td>17.853587</td>\n",
              "      <td>-21.069954</td>\n",
              "      <td>-15.933212</td>\n",
              "      <td>-9.016039</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.889685</td>\n",
              "      <td>54.052330</td>\n",
              "      <td>-6.109238</td>\n",
              "      <td>12.154595</td>\n",
              "      <td>6.095989</td>\n",
              "      <td>-40.195088</td>\n",
              "      <td>-3.958124</td>\n",
              "      <td>-8.079537</td>\n",
              "      <td>-5.160090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>-2.211629</td>\n",
              "      <td>-1.930904</td>\n",
              "      <td>21.888406</td>\n",
              "      <td>-3.067560</td>\n",
              "      <td>-0.240634</td>\n",
              "      <td>2.985056</td>\n",
              "      <td>-29.073369</td>\n",
              "      <td>0.200774</td>\n",
              "      <td>-1.043742</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.126170</td>\n",
              "      <td>-1.035526</td>\n",
              "      <td>2.178769</td>\n",
              "      <td>10.032723</td>\n",
              "      <td>-1.010897</td>\n",
              "      <td>-3.912848</td>\n",
              "      <td>-2.980338</td>\n",
              "      <td>-12.983597</td>\n",
              "      <td>-3.001077</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3.953852</td>\n",
              "      <td>2.964892</td>\n",
              "      <td>-36.044802</td>\n",
              "      <td>0.899838</td>\n",
              "      <td>26.930210</td>\n",
              "      <td>11.004409</td>\n",
              "      <td>-21.962423</td>\n",
              "      <td>-11.950189</td>\n",
              "      <td>-20.933785</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.051761</td>\n",
              "      <td>10.917567</td>\n",
              "      <td>1.905335</td>\n",
              "      <td>-13.004707</td>\n",
              "      <td>17.169552</td>\n",
              "      <td>2.105194</td>\n",
              "      <td>3.967986</td>\n",
              "      <td>11.861657</td>\n",
              "      <td>-27.088846</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3f7f4fe-9635-4461-80f3-2715ad77af5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3f7f4fe-9635-4461-80f3-2715ad77af5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3f7f4fe-9635-4461-80f3-2715ad77af5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id   sensor_1  sensor_2   sensor_3   sensor_4   sensor_5   sensor_6  \\\n",
              "0   1  -6.149463 -0.929714   9.058368  -7.017854  -2.958471   0.179233   \n",
              "1   2  -2.238836 -1.003511   5.098079 -10.880357  -0.804562  -2.992123   \n",
              "2   3  19.087934 -2.092514   0.946750 -21.831788   9.119235  17.853587   \n",
              "3   4  -2.211629 -1.930904  21.888406  -3.067560  -0.240634   2.985056   \n",
              "4   5   3.953852  2.964892 -36.044802   0.899838  26.930210  11.004409   \n",
              "\n",
              "    sensor_7   sensor_8   sensor_9  ...  sensor_24  sensor_25  sensor_26  \\\n",
              "0  -0.956591  -0.972401   5.956213  ...  -7.026436  -6.006282  -6.005836   \n",
              "1  26.972724  -8.900861  -5.968298  ...  -1.996714  -7.933806  -3.136773   \n",
              "2 -21.069954 -15.933212  -9.016039  ...  -6.889685  54.052330  -6.109238   \n",
              "3 -29.073369   0.200774  -1.043742  ...  -2.126170  -1.035526   2.178769   \n",
              "4 -21.962423 -11.950189 -20.933785  ...  -2.051761  10.917567   1.905335   \n",
              "\n",
              "   sensor_27  sensor_28  sensor_29  sensor_30  sensor_31  sensor_32  target  \n",
              "0   7.043084  21.884650  -3.064152  -5.247552  -6.026107 -11.990822       1  \n",
              "1   8.774211  10.944759   9.858186  -0.969241  -3.935553 -15.892421       1  \n",
              "2  12.154595   6.095989 -40.195088  -3.958124  -8.079537  -5.160090       0  \n",
              "3  10.032723  -1.010897  -3.912848  -2.980338 -12.983597  -3.001077       1  \n",
              "4 -13.004707  17.169552   2.105194   3.967986  11.861657 -27.088846       2  \n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f2_dkNz4uKL",
        "outputId": "bf019777-b46e-4e3a-f69c-022a88aa659f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2335, 34)\n",
            "(9343, 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zYb3XiG44ou",
        "outputId": "23f9793a-70ff-407a-9803-7837f63ccc09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2335 entries, 0 to 2334\n",
            "Data columns (total 34 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   id         2335 non-null   int64  \n",
            " 1   sensor_1   2335 non-null   float64\n",
            " 2   sensor_2   2335 non-null   float64\n",
            " 3   sensor_3   2335 non-null   float64\n",
            " 4   sensor_4   2335 non-null   float64\n",
            " 5   sensor_5   2335 non-null   float64\n",
            " 6   sensor_6   2335 non-null   float64\n",
            " 7   sensor_7   2335 non-null   float64\n",
            " 8   sensor_8   2335 non-null   float64\n",
            " 9   sensor_9   2335 non-null   float64\n",
            " 10  sensor_10  2335 non-null   float64\n",
            " 11  sensor_11  2335 non-null   float64\n",
            " 12  sensor_12  2335 non-null   float64\n",
            " 13  sensor_13  2335 non-null   float64\n",
            " 14  sensor_14  2335 non-null   float64\n",
            " 15  sensor_15  2335 non-null   float64\n",
            " 16  sensor_16  2335 non-null   float64\n",
            " 17  sensor_17  2335 non-null   float64\n",
            " 18  sensor_18  2335 non-null   float64\n",
            " 19  sensor_19  2335 non-null   float64\n",
            " 20  sensor_20  2335 non-null   float64\n",
            " 21  sensor_21  2335 non-null   float64\n",
            " 22  sensor_22  2335 non-null   float64\n",
            " 23  sensor_23  2335 non-null   float64\n",
            " 24  sensor_24  2335 non-null   float64\n",
            " 25  sensor_25  2335 non-null   float64\n",
            " 26  sensor_26  2335 non-null   float64\n",
            " 27  sensor_27  2335 non-null   float64\n",
            " 28  sensor_28  2335 non-null   float64\n",
            " 29  sensor_29  2335 non-null   float64\n",
            " 30  sensor_30  2335 non-null   float64\n",
            " 31  sensor_31  2335 non-null   float64\n",
            " 32  sensor_32  2335 non-null   float64\n",
            " 33  target     2335 non-null   int64  \n",
            "dtypes: float64(32), int64(2)\n",
            "memory usage: 620.4 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6qcu7LP5QO3",
        "outputId": "9b5fbe3f-c3b5-4761-ec71-f5e1304865f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    599\n",
              "2    593\n",
              "1    574\n",
              "0    569\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[12,8]) #시각화 자료 사이즈\n",
        "plt.text(s=\"Target variables\",x=0,y=1.3, va='bottom',ha='center',color='#189AB4',fontsize=25)#시각화 자료 텍스트 \n",
        "plt.pie(train['target'].value_counts(),autopct='%1.1f%%', pctdistance=1.1)#히스토그램\n",
        "plt.legend(['3', '2', '1', '0'], loc = \"upper right\",title=\"Programming Languages\", prop={'size': 15})#라벨\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "Yk9kE-us5ckW",
        "outputId": "5a27449b-0724-4037-d547-85746014ce30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yod2k2YIUQHm",
        "outputId": "724838e0-1299-4dcb-c909-ed73772eb127"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b67cb958-acab-4322-a922-8728a2197988\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>1168.000000</td>\n",
              "      <td>674.200761</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>584.500000</td>\n",
              "      <td>1168.000000</td>\n",
              "      <td>1751.500000</td>\n",
              "      <td>2335.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_1</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-1.122174</td>\n",
              "      <td>11.486353</td>\n",
              "      <td>-94.746969</td>\n",
              "      <td>-4.036597</td>\n",
              "      <td>-0.951398</td>\n",
              "      <td>2.895540</td>\n",
              "      <td>68.876142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_2</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-1.024673</td>\n",
              "      <td>7.399859</td>\n",
              "      <td>-63.942094</td>\n",
              "      <td>-4.031957</td>\n",
              "      <td>-1.015582</td>\n",
              "      <td>2.140456</td>\n",
              "      <td>39.913391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_3</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.672769</td>\n",
              "      <td>26.519159</td>\n",
              "      <td>-122.195138</td>\n",
              "      <td>-14.878500</td>\n",
              "      <td>-0.961088</td>\n",
              "      <td>13.974075</td>\n",
              "      <td>127.124171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_4</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.147724</td>\n",
              "      <td>15.551500</td>\n",
              "      <td>-111.870691</td>\n",
              "      <td>-7.116633</td>\n",
              "      <td>-0.890469</td>\n",
              "      <td>6.110973</td>\n",
              "      <td>102.015561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_5</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.327494</td>\n",
              "      <td>11.461970</td>\n",
              "      <td>-94.147972</td>\n",
              "      <td>-3.968687</td>\n",
              "      <td>-0.871690</td>\n",
              "      <td>2.970387</td>\n",
              "      <td>89.059852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_6</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.423462</td>\n",
              "      <td>7.314322</td>\n",
              "      <td>-70.916786</td>\n",
              "      <td>-3.957699</td>\n",
              "      <td>-0.804810</td>\n",
              "      <td>3.006144</td>\n",
              "      <td>34.923040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_7</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>0.676275</td>\n",
              "      <td>26.869479</td>\n",
              "      <td>-105.956553</td>\n",
              "      <td>-13.937806</td>\n",
              "      <td>0.058910</td>\n",
              "      <td>13.934438</td>\n",
              "      <td>120.046277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_8</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.936019</td>\n",
              "      <td>15.598104</td>\n",
              "      <td>-102.965354</td>\n",
              "      <td>-8.053214</td>\n",
              "      <td>-1.095551</td>\n",
              "      <td>4.955494</td>\n",
              "      <td>125.160611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_9</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.797432</td>\n",
              "      <td>12.015022</td>\n",
              "      <td>-81.268085</td>\n",
              "      <td>-4.031148</td>\n",
              "      <td>-0.944613</td>\n",
              "      <td>2.235557</td>\n",
              "      <td>74.101715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_10</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.704585</td>\n",
              "      <td>7.384626</td>\n",
              "      <td>-47.937561</td>\n",
              "      <td>-3.983620</td>\n",
              "      <td>-0.932964</td>\n",
              "      <td>2.883284</td>\n",
              "      <td>47.030119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_11</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-1.099322</td>\n",
              "      <td>26.262009</td>\n",
              "      <td>-115.943693</td>\n",
              "      <td>-15.165419</td>\n",
              "      <td>-1.116522</td>\n",
              "      <td>13.022905</td>\n",
              "      <td>127.110419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_12</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.843473</td>\n",
              "      <td>15.498328</td>\n",
              "      <td>-102.916207</td>\n",
              "      <td>-8.082508</td>\n",
              "      <td>-1.054003</td>\n",
              "      <td>6.021600</td>\n",
              "      <td>99.932331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_13</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.491915</td>\n",
              "      <td>11.894939</td>\n",
              "      <td>-115.053373</td>\n",
              "      <td>-3.893967</td>\n",
              "      <td>-0.908079</td>\n",
              "      <td>2.992981</td>\n",
              "      <td>107.910041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_14</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.851473</td>\n",
              "      <td>7.401702</td>\n",
              "      <td>-59.689434</td>\n",
              "      <td>-3.982224</td>\n",
              "      <td>-0.937905</td>\n",
              "      <td>2.854699</td>\n",
              "      <td>40.026878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_15</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.344029</td>\n",
              "      <td>25.815937</td>\n",
              "      <td>-107.985386</td>\n",
              "      <td>-14.953749</td>\n",
              "      <td>-0.858820</td>\n",
              "      <td>12.965905</td>\n",
              "      <td>126.981907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_16</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-1.128676</td>\n",
              "      <td>15.513633</td>\n",
              "      <td>-126.950747</td>\n",
              "      <td>-8.096568</td>\n",
              "      <td>-1.004242</td>\n",
              "      <td>5.508252</td>\n",
              "      <td>120.974880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_17</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.959658</td>\n",
              "      <td>11.654236</td>\n",
              "      <td>-95.956853</td>\n",
              "      <td>-4.038010</td>\n",
              "      <td>-0.947597</td>\n",
              "      <td>2.895085</td>\n",
              "      <td>85.952050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_18</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.639778</td>\n",
              "      <td>7.586333</td>\n",
              "      <td>-83.854213</td>\n",
              "      <td>-3.996916</td>\n",
              "      <td>-0.967231</td>\n",
              "      <td>2.876743</td>\n",
              "      <td>39.993408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_19</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.559455</td>\n",
              "      <td>26.885734</td>\n",
              "      <td>-108.964270</td>\n",
              "      <td>-15.179515</td>\n",
              "      <td>-0.964579</td>\n",
              "      <td>13.978336</td>\n",
              "      <td>117.934200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_20</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.658692</td>\n",
              "      <td>15.936823</td>\n",
              "      <td>-108.094304</td>\n",
              "      <td>-7.851749</td>\n",
              "      <td>-1.013369</td>\n",
              "      <td>5.917309</td>\n",
              "      <td>121.026042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_21</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.611461</td>\n",
              "      <td>11.942224</td>\n",
              "      <td>-103.876936</td>\n",
              "      <td>-4.002134</td>\n",
              "      <td>-0.942706</td>\n",
              "      <td>2.948692</td>\n",
              "      <td>102.882569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_22</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.741168</td>\n",
              "      <td>7.548507</td>\n",
              "      <td>-59.993001</td>\n",
              "      <td>-3.973502</td>\n",
              "      <td>-0.968065</td>\n",
              "      <td>2.920789</td>\n",
              "      <td>40.917741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_23</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>0.027448</td>\n",
              "      <td>26.671928</td>\n",
              "      <td>-93.171275</td>\n",
              "      <td>-14.102903</td>\n",
              "      <td>-1.104314</td>\n",
              "      <td>12.137937</td>\n",
              "      <td>121.959404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_24</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.356441</td>\n",
              "      <td>16.531906</td>\n",
              "      <td>-127.797649</td>\n",
              "      <td>-7.980628</td>\n",
              "      <td>-0.926120</td>\n",
              "      <td>6.002985</td>\n",
              "      <td>127.161055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_25</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.927744</td>\n",
              "      <td>12.021560</td>\n",
              "      <td>-99.115177</td>\n",
              "      <td>-4.004750</td>\n",
              "      <td>-0.907301</td>\n",
              "      <td>2.863184</td>\n",
              "      <td>58.113657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_26</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.589060</td>\n",
              "      <td>7.440983</td>\n",
              "      <td>-86.193378</td>\n",
              "      <td>-4.001112</td>\n",
              "      <td>-0.897015</td>\n",
              "      <td>2.951682</td>\n",
              "      <td>59.105536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_27</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.081374</td>\n",
              "      <td>25.923355</td>\n",
              "      <td>-105.751637</td>\n",
              "      <td>-14.096840</td>\n",
              "      <td>-0.954791</td>\n",
              "      <td>13.903783</td>\n",
              "      <td>123.179253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_28</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.370812</td>\n",
              "      <td>15.541803</td>\n",
              "      <td>-105.890010</td>\n",
              "      <td>-8.004561</td>\n",
              "      <td>-0.989293</td>\n",
              "      <td>5.922250</td>\n",
              "      <td>111.137925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_29</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.726941</td>\n",
              "      <td>11.636507</td>\n",
              "      <td>-74.977182</td>\n",
              "      <td>-3.981055</td>\n",
              "      <td>-0.889780</td>\n",
              "      <td>2.972719</td>\n",
              "      <td>54.098746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_30</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.809534</td>\n",
              "      <td>7.469744</td>\n",
              "      <td>-74.006065</td>\n",
              "      <td>-3.988965</td>\n",
              "      <td>-0.928504</td>\n",
              "      <td>2.519426</td>\n",
              "      <td>35.896503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_31</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.495062</td>\n",
              "      <td>25.291238</td>\n",
              "      <td>-121.097086</td>\n",
              "      <td>-13.998874</td>\n",
              "      <td>-0.955684</td>\n",
              "      <td>13.926128</td>\n",
              "      <td>125.974107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_32</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>-0.743585</td>\n",
              "      <td>16.300385</td>\n",
              "      <td>-123.876153</td>\n",
              "      <td>-7.873898</td>\n",
              "      <td>-1.019547</td>\n",
              "      <td>5.121679</td>\n",
              "      <td>104.959621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>2335.0</td>\n",
              "      <td>1.523340</td>\n",
              "      <td>1.118221</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b67cb958-acab-4322-a922-8728a2197988')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b67cb958-acab-4322-a922-8728a2197988 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b67cb958-acab-4322-a922-8728a2197988');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            count         mean         std         min         25%  \\\n",
              "id         2335.0  1168.000000  674.200761    1.000000  584.500000   \n",
              "sensor_1   2335.0    -1.122174   11.486353  -94.746969   -4.036597   \n",
              "sensor_2   2335.0    -1.024673    7.399859  -63.942094   -4.031957   \n",
              "sensor_3   2335.0    -0.672769   26.519159 -122.195138  -14.878500   \n",
              "sensor_4   2335.0    -0.147724   15.551500 -111.870691   -7.116633   \n",
              "sensor_5   2335.0    -0.327494   11.461970  -94.147972   -3.968687   \n",
              "sensor_6   2335.0    -0.423462    7.314322  -70.916786   -3.957699   \n",
              "sensor_7   2335.0     0.676275   26.869479 -105.956553  -13.937806   \n",
              "sensor_8   2335.0    -0.936019   15.598104 -102.965354   -8.053214   \n",
              "sensor_9   2335.0    -0.797432   12.015022  -81.268085   -4.031148   \n",
              "sensor_10  2335.0    -0.704585    7.384626  -47.937561   -3.983620   \n",
              "sensor_11  2335.0    -1.099322   26.262009 -115.943693  -15.165419   \n",
              "sensor_12  2335.0    -0.843473   15.498328 -102.916207   -8.082508   \n",
              "sensor_13  2335.0    -0.491915   11.894939 -115.053373   -3.893967   \n",
              "sensor_14  2335.0    -0.851473    7.401702  -59.689434   -3.982224   \n",
              "sensor_15  2335.0    -0.344029   25.815937 -107.985386  -14.953749   \n",
              "sensor_16  2335.0    -1.128676   15.513633 -126.950747   -8.096568   \n",
              "sensor_17  2335.0    -0.959658   11.654236  -95.956853   -4.038010   \n",
              "sensor_18  2335.0    -0.639778    7.586333  -83.854213   -3.996916   \n",
              "sensor_19  2335.0    -0.559455   26.885734 -108.964270  -15.179515   \n",
              "sensor_20  2335.0    -0.658692   15.936823 -108.094304   -7.851749   \n",
              "sensor_21  2335.0    -0.611461   11.942224 -103.876936   -4.002134   \n",
              "sensor_22  2335.0    -0.741168    7.548507  -59.993001   -3.973502   \n",
              "sensor_23  2335.0     0.027448   26.671928  -93.171275  -14.102903   \n",
              "sensor_24  2335.0    -0.356441   16.531906 -127.797649   -7.980628   \n",
              "sensor_25  2335.0    -0.927744   12.021560  -99.115177   -4.004750   \n",
              "sensor_26  2335.0    -0.589060    7.440983  -86.193378   -4.001112   \n",
              "sensor_27  2335.0    -0.081374   25.923355 -105.751637  -14.096840   \n",
              "sensor_28  2335.0    -0.370812   15.541803 -105.890010   -8.004561   \n",
              "sensor_29  2335.0    -0.726941   11.636507  -74.977182   -3.981055   \n",
              "sensor_30  2335.0    -0.809534    7.469744  -74.006065   -3.988965   \n",
              "sensor_31  2335.0    -0.495062   25.291238 -121.097086  -13.998874   \n",
              "sensor_32  2335.0    -0.743585   16.300385 -123.876153   -7.873898   \n",
              "target     2335.0     1.523340    1.118221    0.000000    1.000000   \n",
              "\n",
              "                   50%          75%          max  \n",
              "id         1168.000000  1751.500000  2335.000000  \n",
              "sensor_1     -0.951398     2.895540    68.876142  \n",
              "sensor_2     -1.015582     2.140456    39.913391  \n",
              "sensor_3     -0.961088    13.974075   127.124171  \n",
              "sensor_4     -0.890469     6.110973   102.015561  \n",
              "sensor_5     -0.871690     2.970387    89.059852  \n",
              "sensor_6     -0.804810     3.006144    34.923040  \n",
              "sensor_7      0.058910    13.934438   120.046277  \n",
              "sensor_8     -1.095551     4.955494   125.160611  \n",
              "sensor_9     -0.944613     2.235557    74.101715  \n",
              "sensor_10    -0.932964     2.883284    47.030119  \n",
              "sensor_11    -1.116522    13.022905   127.110419  \n",
              "sensor_12    -1.054003     6.021600    99.932331  \n",
              "sensor_13    -0.908079     2.992981   107.910041  \n",
              "sensor_14    -0.937905     2.854699    40.026878  \n",
              "sensor_15    -0.858820    12.965905   126.981907  \n",
              "sensor_16    -1.004242     5.508252   120.974880  \n",
              "sensor_17    -0.947597     2.895085    85.952050  \n",
              "sensor_18    -0.967231     2.876743    39.993408  \n",
              "sensor_19    -0.964579    13.978336   117.934200  \n",
              "sensor_20    -1.013369     5.917309   121.026042  \n",
              "sensor_21    -0.942706     2.948692   102.882569  \n",
              "sensor_22    -0.968065     2.920789    40.917741  \n",
              "sensor_23    -1.104314    12.137937   121.959404  \n",
              "sensor_24    -0.926120     6.002985   127.161055  \n",
              "sensor_25    -0.907301     2.863184    58.113657  \n",
              "sensor_26    -0.897015     2.951682    59.105536  \n",
              "sensor_27    -0.954791    13.903783   123.179253  \n",
              "sensor_28    -0.989293     5.922250   111.137925  \n",
              "sensor_29    -0.889780     2.972719    54.098746  \n",
              "sensor_30    -0.928504     2.519426    35.896503  \n",
              "sensor_31    -0.955684    13.926128   125.974107  \n",
              "sensor_32    -1.019547     5.121679   104.959621  \n",
              "target        2.000000     3.000000     3.000000  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train.drop(['id', 'target'], axis = 1)\n",
        "test_x = test.drop(['id'], axis = 1)\n",
        "\n",
        "mins = train_x.min()\n",
        "maxs = train_x.max()\n",
        "mins[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-6wXtmWUeIP",
        "outputId": "f3580497-2c9f-4c51-995f-2be1b9c11ae8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sensor_1    -94.746969\n",
              "sensor_2    -63.942094\n",
              "sensor_3   -122.195138\n",
              "sensor_4   -111.870691\n",
              "sensor_5    -94.147972\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = (train_x - mins) / (maxs - mins)\n",
        "test_x = (test_x - mins) / (maxs - mins)\n",
        "train_x.describe().T[['min', 'max']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PTYFksEhUr7T",
        "outputId": "129d631c-2ce5-425d-b706-e6f7758ee72b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cd46e5f5-6aa9-4dcb-8832-41f8970df907\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sensor_1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_18</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_21</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_23</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_25</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_28</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_30</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensor_32</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd46e5f5-6aa9-4dcb-8832-41f8970df907')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd46e5f5-6aa9-4dcb-8832-41f8970df907 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd46e5f5-6aa9-4dcb-8832-41f8970df907');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           min  max\n",
              "sensor_1   0.0  1.0\n",
              "sensor_2   0.0  1.0\n",
              "sensor_3   0.0  1.0\n",
              "sensor_4   0.0  1.0\n",
              "sensor_5   0.0  1.0\n",
              "sensor_6   0.0  1.0\n",
              "sensor_7   0.0  1.0\n",
              "sensor_8   0.0  1.0\n",
              "sensor_9   0.0  1.0\n",
              "sensor_10  0.0  1.0\n",
              "sensor_11  0.0  1.0\n",
              "sensor_12  0.0  1.0\n",
              "sensor_13  0.0  1.0\n",
              "sensor_14  0.0  1.0\n",
              "sensor_15  0.0  1.0\n",
              "sensor_16  0.0  1.0\n",
              "sensor_17  0.0  1.0\n",
              "sensor_18  0.0  1.0\n",
              "sensor_19  0.0  1.0\n",
              "sensor_20  0.0  1.0\n",
              "sensor_21  0.0  1.0\n",
              "sensor_22  0.0  1.0\n",
              "sensor_23  0.0  1.0\n",
              "sensor_24  0.0  1.0\n",
              "sensor_25  0.0  1.0\n",
              "sensor_26  0.0  1.0\n",
              "sensor_27  0.0  1.0\n",
              "sensor_28  0.0  1.0\n",
              "sensor_29  0.0  1.0\n",
              "sensor_30  0.0  1.0\n",
              "sensor_31  0.0  1.0\n",
              "sensor_32  0.0  1.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad5QNDn0VCxU",
        "outputId": "1f6dd73e-f522-46ad-c89b-a4475af93b4a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3ad83ff710>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = torch.from_numpy(train_x.to_numpy()).float()\n",
        "train_y = torch.tensor(train['target'].to_numpy(), dtype = torch.int64)\n",
        "\n",
        "test_x = torch.from_numpy(test_x.to_numpy()).float()\n",
        "\n",
        "train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqjO38TzVLbs",
        "outputId": "0b0eea80-e461-4460-d0e3-25da14693013"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5415, 0.6067, 0.5264,  ..., 0.6256, 0.4657, 0.4889],\n",
              "        [0.5654, 0.6060, 0.5106,  ..., 0.6646, 0.4742, 0.4719],\n",
              "        [0.6957, 0.5955, 0.4939,  ..., 0.6374, 0.4574, 0.5188],\n",
              "        ...,\n",
              "        [0.5240, 0.6733, 0.4574,  ..., 0.5721, 0.4617, 0.5373],\n",
              "        [0.5547, 0.6447, 0.4422,  ..., 0.6371, 0.5505, 0.4885],\n",
              "        [0.5678, 0.5481, 0.3061,  ..., 0.6840, 0.4012, 0.4843]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(train_x, train_y)\n",
        "\n",
        "print(train_dataset.__len__())\n",
        "print(train_dataset.__getitem__(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi-fDWSYVOo9",
        "outputId": "a54ca136-8c25-4f9c-ba4a-4020751c2fe4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2335\n",
            "(tensor([0.5654, 0.6060, 0.5106, 0.4722, 0.5095, 0.6418, 0.5882, 0.4123, 0.4846,\n",
            "        0.4620, 0.4892, 0.4825, 0.5209, 0.6385, 0.3529, 0.5038, 0.5435, 0.6448,\n",
            "        0.5070, 0.4935, 0.5120, 0.5833, 0.5024, 0.4934, 0.5799, 0.5716, 0.5003,\n",
            "        0.5383, 0.6573, 0.6646, 0.4742, 0.4719]), tensor(1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size = 16, shuffle = True)\n",
        "\n",
        "for batch_idx, samples in enumerate(train_dataloader):\n",
        "    if batch_idx > 0:\n",
        "        break\n",
        "    print(samples[0].shape)\n",
        "    print(samples[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l9luTtzVPj8",
        "outputId": "e0056598-3851-4e4a-c1c6-590a0ca93d04"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 32])\n",
            "tensor([1, 3, 1, 1, 1, 2, 1, 0, 3, 0, 3, 0, 3, 2, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Models(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(32, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 4),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_relu_stack(x)\n",
        "        return x\n",
        "\n",
        "model = Models()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yng3bsvjVmOA",
        "outputId": "2f82472d-b55c-4c01-e7c4-b7cc86b98623"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models(\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.2, inplace=False)\n",
            "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
            "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): Dropout(p=0.2, inplace=False)\n",
            "    (8): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): Dropout(p=0.2, inplace=False)\n",
            "    (12): Linear(in_features=256, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    accuracy = 0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad() # 매개변수를 0으로 만듭니다. 매 학습시 초기화해줘야합니다.\n",
        "        outputs = model(inputs) # 입력값을 넣어 순전파를 진행시킵니다.\n",
        "\n",
        "        loss = criterion(outputs, labels) # 모델 출력값와 실제값을 손실함수에 대입합니다.\n",
        "        loss.backward() # 손실함수에서 역전파 수행합니다.\n",
        "        optimizer.step() # 옵티마이저를 사용해 매개변수를 최적화합니다.\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                accuracy = accuracy + 1\n",
        "\n",
        "    \n",
        "    print(f'{epoch + 1} 에포크 loss: {running_loss / i:.3f}')\n",
        "    print(f'{epoch + 1} 에포크 정확도: {accuracy / (i * 16):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agNrA9U5VuDP",
        "outputId": "437b85e0-0de2-42c2-bd31-c823fb6c1244"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 에포크 loss: 1.295\n",
            "1 에포크 정확도: 0.393\n",
            "2 에포크 loss: 1.136\n",
            "2 에포크 정확도: 0.502\n",
            "3 에포크 loss: 1.039\n",
            "3 에포크 정확도: 0.581\n",
            "4 에포크 loss: 0.977\n",
            "4 에포크 정확도: 0.599\n",
            "5 에포크 loss: 0.932\n",
            "5 에포크 정확도: 0.634\n",
            "6 에포크 loss: 0.900\n",
            "6 에포크 정확도: 0.639\n",
            "7 에포크 loss: 0.875\n",
            "7 에포크 정확도: 0.651\n",
            "8 에포크 loss: 0.847\n",
            "8 에포크 정확도: 0.664\n",
            "9 에포크 loss: 0.813\n",
            "9 에포크 정확도: 0.678\n",
            "10 에포크 loss: 0.780\n",
            "10 에포크 정확도: 0.692\n",
            "11 에포크 loss: 0.806\n",
            "11 에포크 정확도: 0.687\n",
            "12 에포크 loss: 0.766\n",
            "12 에포크 정확도: 0.711\n",
            "13 에포크 loss: 0.757\n",
            "13 에포크 정확도: 0.709\n",
            "14 에포크 loss: 0.735\n",
            "14 에포크 정확도: 0.713\n",
            "15 에포크 loss: 0.741\n",
            "15 에포크 정확도: 0.708\n",
            "16 에포크 loss: 0.730\n",
            "16 에포크 정확도: 0.728\n",
            "17 에포크 loss: 0.729\n",
            "17 에포크 정확도: 0.720\n",
            "18 에포크 loss: 0.693\n",
            "18 에포크 정확도: 0.730\n",
            "19 에포크 loss: 0.691\n",
            "19 에포크 정확도: 0.724\n",
            "20 에포크 loss: 0.697\n",
            "20 에포크 정확도: 0.740\n",
            "21 에포크 loss: 0.680\n",
            "21 에포크 정확도: 0.741\n",
            "22 에포크 loss: 0.676\n",
            "22 에포크 정확도: 0.740\n",
            "23 에포크 loss: 0.670\n",
            "23 에포크 정확도: 0.747\n",
            "24 에포크 loss: 0.680\n",
            "24 에포크 정확도: 0.734\n",
            "25 에포크 loss: 0.641\n",
            "25 에포크 정확도: 0.750\n",
            "26 에포크 loss: 0.668\n",
            "26 에포크 정확도: 0.746\n",
            "27 에포크 loss: 0.649\n",
            "27 에포크 정확도: 0.758\n",
            "28 에포크 loss: 0.635\n",
            "28 에포크 정확도: 0.747\n",
            "29 에포크 loss: 0.632\n",
            "29 에포크 정확도: 0.754\n",
            "30 에포크 loss: 0.625\n",
            "30 에포크 정확도: 0.771\n",
            "31 에포크 loss: 0.634\n",
            "31 에포크 정확도: 0.751\n",
            "32 에포크 loss: 0.640\n",
            "32 에포크 정확도: 0.752\n",
            "33 에포크 loss: 0.618\n",
            "33 에포크 정확도: 0.771\n",
            "34 에포크 loss: 0.647\n",
            "34 에포크 정확도: 0.753\n",
            "35 에포크 loss: 0.616\n",
            "35 에포크 정확도: 0.768\n",
            "36 에포크 loss: 0.613\n",
            "36 에포크 정확도: 0.762\n",
            "37 에포크 loss: 0.626\n",
            "37 에포크 정확도: 0.759\n",
            "38 에포크 loss: 0.631\n",
            "38 에포크 정확도: 0.765\n",
            "39 에포크 loss: 0.613\n",
            "39 에포크 정확도: 0.781\n",
            "40 에포크 loss: 0.571\n",
            "40 에포크 정확도: 0.791\n",
            "41 에포크 loss: 0.610\n",
            "41 에포크 정확도: 0.762\n",
            "42 에포크 loss: 0.591\n",
            "42 에포크 정확도: 0.775\n",
            "43 에포크 loss: 0.563\n",
            "43 에포크 정확도: 0.782\n",
            "44 에포크 loss: 0.559\n",
            "44 에포크 정확도: 0.782\n",
            "45 에포크 loss: 0.612\n",
            "45 에포크 정확도: 0.765\n",
            "46 에포크 loss: 0.577\n",
            "46 에포크 정확도: 0.781\n",
            "47 에포크 loss: 0.578\n",
            "47 에포크 정확도: 0.774\n",
            "48 에포크 loss: 0.591\n",
            "48 에포크 정확도: 0.777\n",
            "49 에포크 loss: 0.572\n",
            "49 에포크 정확도: 0.790\n",
            "50 에포크 loss: 0.559\n",
            "50 에포크 정확도: 0.791\n",
            "51 에포크 loss: 0.562\n",
            "51 에포크 정확도: 0.798\n",
            "52 에포크 loss: 0.584\n",
            "52 에포크 정확도: 0.781\n",
            "53 에포크 loss: 0.571\n",
            "53 에포크 정확도: 0.785\n",
            "54 에포크 loss: 0.572\n",
            "54 에포크 정확도: 0.792\n",
            "55 에포크 loss: 0.567\n",
            "55 에포크 정확도: 0.783\n",
            "56 에포크 loss: 0.562\n",
            "56 에포크 정확도: 0.790\n",
            "57 에포크 loss: 0.552\n",
            "57 에포크 정확도: 0.804\n",
            "58 에포크 loss: 0.564\n",
            "58 에포크 정확도: 0.790\n",
            "59 에포크 loss: 0.551\n",
            "59 에포크 정확도: 0.787\n",
            "60 에포크 loss: 0.573\n",
            "60 에포크 정확도: 0.786\n",
            "61 에포크 loss: 0.546\n",
            "61 에포크 정확도: 0.792\n",
            "62 에포크 loss: 0.555\n",
            "62 에포크 정확도: 0.791\n",
            "63 에포크 loss: 0.570\n",
            "63 에포크 정확도: 0.793\n",
            "64 에포크 loss: 0.556\n",
            "64 에포크 정확도: 0.791\n",
            "65 에포크 loss: 0.568\n",
            "65 에포크 정확도: 0.793\n",
            "66 에포크 loss: 0.571\n",
            "66 에포크 정확도: 0.788\n",
            "67 에포크 loss: 0.547\n",
            "67 에포크 정확도: 0.797\n",
            "68 에포크 loss: 0.528\n",
            "68 에포크 정확도: 0.811\n",
            "69 에포크 loss: 0.526\n",
            "69 에포크 정확도: 0.808\n",
            "70 에포크 loss: 0.541\n",
            "70 에포크 정확도: 0.797\n",
            "71 에포크 loss: 0.547\n",
            "71 에포크 정확도: 0.797\n",
            "72 에포크 loss: 0.526\n",
            "72 에포크 정확도: 0.812\n",
            "73 에포크 loss: 0.540\n",
            "73 에포크 정확도: 0.803\n",
            "74 에포크 loss: 0.520\n",
            "74 에포크 정확도: 0.803\n",
            "75 에포크 loss: 0.558\n",
            "75 에포크 정확도: 0.791\n",
            "76 에포크 loss: 0.519\n",
            "76 에포크 정확도: 0.804\n",
            "77 에포크 loss: 0.535\n",
            "77 에포크 정확도: 0.798\n",
            "78 에포크 loss: 0.535\n",
            "78 에포크 정확도: 0.803\n",
            "79 에포크 loss: 0.528\n",
            "79 에포크 정확도: 0.804\n",
            "80 에포크 loss: 0.533\n",
            "80 에포크 정확도: 0.801\n",
            "81 에포크 loss: 0.555\n",
            "81 에포크 정확도: 0.796\n",
            "82 에포크 loss: 0.529\n",
            "82 에포크 정확도: 0.800\n",
            "83 에포크 loss: 0.528\n",
            "83 에포크 정확도: 0.809\n",
            "84 에포크 loss: 0.517\n",
            "84 에포크 정확도: 0.805\n",
            "85 에포크 loss: 0.518\n",
            "85 에포크 정확도: 0.806\n",
            "86 에포크 loss: 0.550\n",
            "86 에포크 정확도: 0.789\n",
            "87 에포크 loss: 0.541\n",
            "87 에포크 정확도: 0.805\n",
            "88 에포크 loss: 0.537\n",
            "88 에포크 정확도: 0.803\n",
            "89 에포크 loss: 0.522\n",
            "89 에포크 정확도: 0.806\n",
            "90 에포크 loss: 0.519\n",
            "90 에포크 정확도: 0.810\n",
            "91 에포크 loss: 0.519\n",
            "91 에포크 정확도: 0.800\n",
            "92 에포크 loss: 0.520\n",
            "92 에포크 정확도: 0.802\n",
            "93 에포크 loss: 0.530\n",
            "93 에포크 정확도: 0.815\n",
            "94 에포크 loss: 0.506\n",
            "94 에포크 정확도: 0.812\n",
            "95 에포크 loss: 0.528\n",
            "95 에포크 정확도: 0.806\n",
            "96 에포크 loss: 0.515\n",
            "96 에포크 정확도: 0.812\n",
            "97 에포크 loss: 0.499\n",
            "97 에포크 정확도: 0.824\n",
            "98 에포크 loss: 0.493\n",
            "98 에포크 정확도: 0.819\n",
            "99 에포크 loss: 0.483\n",
            "99 에포크 정확도: 0.817\n",
            "100 에포크 loss: 0.502\n",
            "100 에포크 정확도: 0.805\n",
            "101 에포크 loss: 0.508\n",
            "101 에포크 정확도: 0.809\n",
            "102 에포크 loss: 0.523\n",
            "102 에포크 정확도: 0.802\n",
            "103 에포크 loss: 0.517\n",
            "103 에포크 정확도: 0.803\n",
            "104 에포크 loss: 0.495\n",
            "104 에포크 정확도: 0.819\n",
            "105 에포크 loss: 0.515\n",
            "105 에포크 정확도: 0.816\n",
            "106 에포크 loss: 0.502\n",
            "106 에포크 정확도: 0.818\n",
            "107 에포크 loss: 0.505\n",
            "107 에포크 정확도: 0.809\n",
            "108 에포크 loss: 0.555\n",
            "108 에포크 정확도: 0.787\n",
            "109 에포크 loss: 0.495\n",
            "109 에포크 정확도: 0.823\n",
            "110 에포크 loss: 0.489\n",
            "110 에포크 정확도: 0.818\n",
            "111 에포크 loss: 0.516\n",
            "111 에포크 정확도: 0.810\n",
            "112 에포크 loss: 0.483\n",
            "112 에포크 정확도: 0.812\n",
            "113 에포크 loss: 0.488\n",
            "113 에포크 정확도: 0.831\n",
            "114 에포크 loss: 0.506\n",
            "114 에포크 정확도: 0.806\n",
            "115 에포크 loss: 0.467\n",
            "115 에포크 정확도: 0.831\n",
            "116 에포크 loss: 0.496\n",
            "116 에포크 정확도: 0.818\n",
            "117 에포크 loss: 0.475\n",
            "117 에포크 정확도: 0.821\n",
            "118 에포크 loss: 0.502\n",
            "118 에포크 정확도: 0.819\n",
            "119 에포크 loss: 0.515\n",
            "119 에포크 정확도: 0.812\n",
            "120 에포크 loss: 0.492\n",
            "120 에포크 정확도: 0.814\n",
            "121 에포크 loss: 0.482\n",
            "121 에포크 정확도: 0.822\n",
            "122 에포크 loss: 0.456\n",
            "122 에포크 정확도: 0.829\n",
            "123 에포크 loss: 0.504\n",
            "123 에포크 정확도: 0.824\n",
            "124 에포크 loss: 0.474\n",
            "124 에포크 정확도: 0.823\n",
            "125 에포크 loss: 0.493\n",
            "125 에포크 정확도: 0.820\n",
            "126 에포크 loss: 0.480\n",
            "126 에포크 정확도: 0.823\n",
            "127 에포크 loss: 0.491\n",
            "127 에포크 정확도: 0.823\n",
            "128 에포크 loss: 0.501\n",
            "128 에포크 정확도: 0.814\n",
            "129 에포크 loss: 0.497\n",
            "129 에포크 정확도: 0.809\n",
            "130 에포크 loss: 0.468\n",
            "130 에포크 정확도: 0.828\n",
            "131 에포크 loss: 0.459\n",
            "131 에포크 정확도: 0.828\n",
            "132 에포크 loss: 0.488\n",
            "132 에포크 정확도: 0.815\n",
            "133 에포크 loss: 0.491\n",
            "133 에포크 정확도: 0.814\n",
            "134 에포크 loss: 0.487\n",
            "134 에포크 정확도: 0.815\n",
            "135 에포크 loss: 0.490\n",
            "135 에포크 정확도: 0.819\n",
            "136 에포크 loss: 0.473\n",
            "136 에포크 정확도: 0.835\n",
            "137 에포크 loss: 0.507\n",
            "137 에포크 정확도: 0.819\n",
            "138 에포크 loss: 0.486\n",
            "138 에포크 정확도: 0.826\n",
            "139 에포크 loss: 0.458\n",
            "139 에포크 정확도: 0.833\n",
            "140 에포크 loss: 0.470\n",
            "140 에포크 정확도: 0.827\n",
            "141 에포크 loss: 0.480\n",
            "141 에포크 정확도: 0.818\n",
            "142 에포크 loss: 0.486\n",
            "142 에포크 정확도: 0.816\n",
            "143 에포크 loss: 0.466\n",
            "143 에포크 정확도: 0.825\n",
            "144 에포크 loss: 0.480\n",
            "144 에포크 정확도: 0.825\n",
            "145 에포크 loss: 0.480\n",
            "145 에포크 정확도: 0.828\n",
            "146 에포크 loss: 0.503\n",
            "146 에포크 정확도: 0.816\n",
            "147 에포크 loss: 0.482\n",
            "147 에포크 정확도: 0.823\n",
            "148 에포크 loss: 0.493\n",
            "148 에포크 정확도: 0.824\n",
            "149 에포크 loss: 0.492\n",
            "149 에포크 정확도: 0.813\n",
            "150 에포크 loss: 0.466\n",
            "150 에포크 정확도: 0.839\n",
            "151 에포크 loss: 0.478\n",
            "151 에포크 정확도: 0.827\n",
            "152 에포크 loss: 0.469\n",
            "152 에포크 정확도: 0.823\n",
            "153 에포크 loss: 0.475\n",
            "153 에포크 정확도: 0.826\n",
            "154 에포크 loss: 0.473\n",
            "154 에포크 정확도: 0.832\n",
            "155 에포크 loss: 0.490\n",
            "155 에포크 정확도: 0.818\n",
            "156 에포크 loss: 0.468\n",
            "156 에포크 정확도: 0.825\n",
            "157 에포크 loss: 0.455\n",
            "157 에포크 정확도: 0.834\n",
            "158 에포크 loss: 0.458\n",
            "158 에포크 정확도: 0.833\n",
            "159 에포크 loss: 0.470\n",
            "159 에포크 정확도: 0.821\n",
            "160 에포크 loss: 0.449\n",
            "160 에포크 정확도: 0.839\n",
            "161 에포크 loss: 0.485\n",
            "161 에포크 정확도: 0.825\n",
            "162 에포크 loss: 0.514\n",
            "162 에포크 정확도: 0.819\n",
            "163 에포크 loss: 0.498\n",
            "163 에포크 정확도: 0.818\n",
            "164 에포크 loss: 0.495\n",
            "164 에포크 정확도: 0.833\n",
            "165 에포크 loss: 0.476\n",
            "165 에포크 정확도: 0.820\n",
            "166 에포크 loss: 0.481\n",
            "166 에포크 정확도: 0.825\n",
            "167 에포크 loss: 0.483\n",
            "167 에포크 정확도: 0.817\n",
            "168 에포크 loss: 0.487\n",
            "168 에포크 정확도: 0.821\n",
            "169 에포크 loss: 0.462\n",
            "169 에포크 정확도: 0.837\n",
            "170 에포크 loss: 0.454\n",
            "170 에포크 정확도: 0.834\n",
            "171 에포크 loss: 0.460\n",
            "171 에포크 정확도: 0.839\n",
            "172 에포크 loss: 0.476\n",
            "172 에포크 정확도: 0.833\n",
            "173 에포크 loss: 0.453\n",
            "173 에포크 정확도: 0.828\n",
            "174 에포크 loss: 0.469\n",
            "174 에포크 정확도: 0.826\n",
            "175 에포크 loss: 0.476\n",
            "175 에포크 정확도: 0.837\n",
            "176 에포크 loss: 0.484\n",
            "176 에포크 정확도: 0.827\n",
            "177 에포크 loss: 0.472\n",
            "177 에포크 정확도: 0.831\n",
            "178 에포크 loss: 0.440\n",
            "178 에포크 정확도: 0.838\n",
            "179 에포크 loss: 0.495\n",
            "179 에포크 정확도: 0.825\n",
            "180 에포크 loss: 0.507\n",
            "180 에포크 정확도: 0.812\n",
            "181 에포크 loss: 0.468\n",
            "181 에포크 정확도: 0.822\n",
            "182 에포크 loss: 0.439\n",
            "182 에포크 정확도: 0.848\n",
            "183 에포크 loss: 0.459\n",
            "183 에포크 정확도: 0.835\n",
            "184 에포크 loss: 0.450\n",
            "184 에포크 정확도: 0.839\n",
            "185 에포크 loss: 0.451\n",
            "185 에포크 정확도: 0.834\n",
            "186 에포크 loss: 0.440\n",
            "186 에포크 정확도: 0.844\n",
            "187 에포크 loss: 0.473\n",
            "187 에포크 정확도: 0.838\n",
            "188 에포크 loss: 0.479\n",
            "188 에포크 정확도: 0.827\n",
            "189 에포크 loss: 0.434\n",
            "189 에포크 정확도: 0.844\n",
            "190 에포크 loss: 0.497\n",
            "190 에포크 정확도: 0.818\n",
            "191 에포크 loss: 0.488\n",
            "191 에포크 정확도: 0.822\n",
            "192 에포크 loss: 0.487\n",
            "192 에포크 정확도: 0.823\n",
            "193 에포크 loss: 0.488\n",
            "193 에포크 정확도: 0.819\n",
            "194 에포크 loss: 0.437\n",
            "194 에포크 정확도: 0.845\n",
            "195 에포크 loss: 0.450\n",
            "195 에포크 정확도: 0.832\n",
            "196 에포크 loss: 0.459\n",
            "196 에포크 정확도: 0.836\n",
            "197 에포크 loss: 0.464\n",
            "197 에포크 정확도: 0.823\n",
            "198 에포크 loss: 0.471\n",
            "198 에포크 정확도: 0.828\n",
            "199 에포크 loss: 0.437\n",
            "199 에포크 정확도: 0.845\n",
            "200 에포크 loss: 0.456\n",
            "200 에포크 정확도: 0.842\n",
            "201 에포크 loss: 0.433\n",
            "201 에포크 정확도: 0.847\n",
            "202 에포크 loss: 0.451\n",
            "202 에포크 정확도: 0.830\n",
            "203 에포크 loss: 0.460\n",
            "203 에포크 정확도: 0.834\n",
            "204 에포크 loss: 0.471\n",
            "204 에포크 정확도: 0.823\n",
            "205 에포크 loss: 0.435\n",
            "205 에포크 정확도: 0.835\n",
            "206 에포크 loss: 0.447\n",
            "206 에포크 정확도: 0.832\n",
            "207 에포크 loss: 0.439\n",
            "207 에포크 정확도: 0.840\n",
            "208 에포크 loss: 0.449\n",
            "208 에포크 정확도: 0.855\n",
            "209 에포크 loss: 0.450\n",
            "209 에포크 정확도: 0.835\n",
            "210 에포크 loss: 0.458\n",
            "210 에포크 정확도: 0.839\n",
            "211 에포크 loss: 0.459\n",
            "211 에포크 정확도: 0.838\n",
            "212 에포크 loss: 0.440\n",
            "212 에포크 정확도: 0.844\n",
            "213 에포크 loss: 0.458\n",
            "213 에포크 정확도: 0.844\n",
            "214 에포크 loss: 0.436\n",
            "214 에포크 정확도: 0.840\n",
            "215 에포크 loss: 0.464\n",
            "215 에포크 정확도: 0.830\n",
            "216 에포크 loss: 0.445\n",
            "216 에포크 정확도: 0.835\n",
            "217 에포크 loss: 0.419\n",
            "217 에포크 정확도: 0.847\n",
            "218 에포크 loss: 0.455\n",
            "218 에포크 정확도: 0.838\n",
            "219 에포크 loss: 0.457\n",
            "219 에포크 정확도: 0.834\n",
            "220 에포크 loss: 0.459\n",
            "220 에포크 정확도: 0.833\n",
            "221 에포크 loss: 0.456\n",
            "221 에포크 정확도: 0.835\n",
            "222 에포크 loss: 0.443\n",
            "222 에포크 정확도: 0.838\n",
            "223 에포크 loss: 0.477\n",
            "223 에포크 정확도: 0.820\n",
            "224 에포크 loss: 0.466\n",
            "224 에포크 정확도: 0.835\n",
            "225 에포크 loss: 0.441\n",
            "225 에포크 정확도: 0.843\n",
            "226 에포크 loss: 0.414\n",
            "226 에포크 정확도: 0.844\n",
            "227 에포크 loss: 0.460\n",
            "227 에포크 정확도: 0.836\n",
            "228 에포크 loss: 0.443\n",
            "228 에포크 정확도: 0.828\n",
            "229 에포크 loss: 0.456\n",
            "229 에포크 정확도: 0.837\n",
            "230 에포크 loss: 0.434\n",
            "230 에포크 정확도: 0.840\n",
            "231 에포크 loss: 0.439\n",
            "231 에포크 정확도: 0.844\n",
            "232 에포크 loss: 0.432\n",
            "232 에포크 정확도: 0.853\n",
            "233 에포크 loss: 0.445\n",
            "233 에포크 정확도: 0.831\n",
            "234 에포크 loss: 0.480\n",
            "234 에포크 정확도: 0.826\n",
            "235 에포크 loss: 0.440\n",
            "235 에포크 정확도: 0.838\n",
            "236 에포크 loss: 0.448\n",
            "236 에포크 정확도: 0.837\n",
            "237 에포크 loss: 0.469\n",
            "237 에포크 정확도: 0.829\n",
            "238 에포크 loss: 0.427\n",
            "238 에포크 정확도: 0.851\n",
            "239 에포크 loss: 0.433\n",
            "239 에포크 정확도: 0.844\n",
            "240 에포크 loss: 0.445\n",
            "240 에포크 정확도: 0.834\n",
            "241 에포크 loss: 0.437\n",
            "241 에포크 정확도: 0.835\n",
            "242 에포크 loss: 0.450\n",
            "242 에포크 정확도: 0.843\n",
            "243 에포크 loss: 0.451\n",
            "243 에포크 정확도: 0.838\n",
            "244 에포크 loss: 0.452\n",
            "244 에포크 정확도: 0.838\n",
            "245 에포크 loss: 0.454\n",
            "245 에포크 정확도: 0.838\n",
            "246 에포크 loss: 0.431\n",
            "246 에포크 정확도: 0.844\n",
            "247 에포크 loss: 0.440\n",
            "247 에포크 정확도: 0.844\n",
            "248 에포크 loss: 0.450\n",
            "248 에포크 정확도: 0.840\n",
            "249 에포크 loss: 0.444\n",
            "249 에포크 정확도: 0.838\n",
            "250 에포크 loss: 0.413\n",
            "250 에포크 정확도: 0.847\n",
            "251 에포크 loss: 0.398\n",
            "251 에포크 정확도: 0.863\n",
            "252 에포크 loss: 0.442\n",
            "252 에포크 정확도: 0.846\n",
            "253 에포크 loss: 0.431\n",
            "253 에포크 정확도: 0.843\n",
            "254 에포크 loss: 0.462\n",
            "254 에포크 정확도: 0.843\n",
            "255 에포크 loss: 0.428\n",
            "255 에포크 정확도: 0.840\n",
            "256 에포크 loss: 0.438\n",
            "256 에포크 정확도: 0.845\n",
            "257 에포크 loss: 0.434\n",
            "257 에포크 정확도: 0.851\n",
            "258 에포크 loss: 0.428\n",
            "258 에포크 정확도: 0.851\n",
            "259 에포크 loss: 0.435\n",
            "259 에포크 정확도: 0.841\n",
            "260 에포크 loss: 0.464\n",
            "260 에포크 정확도: 0.834\n",
            "261 에포크 loss: 0.418\n",
            "261 에포크 정확도: 0.846\n",
            "262 에포크 loss: 0.431\n",
            "262 에포크 정확도: 0.844\n",
            "263 에포크 loss: 0.420\n",
            "263 에포크 정확도: 0.853\n",
            "264 에포크 loss: 0.448\n",
            "264 에포크 정확도: 0.843\n",
            "265 에포크 loss: 0.434\n",
            "265 에포크 정확도: 0.841\n",
            "266 에포크 loss: 0.436\n",
            "266 에포크 정확도: 0.843\n",
            "267 에포크 loss: 0.442\n",
            "267 에포크 정확도: 0.839\n",
            "268 에포크 loss: 0.431\n",
            "268 에포크 정확도: 0.848\n",
            "269 에포크 loss: 0.427\n",
            "269 에포크 정확도: 0.845\n",
            "270 에포크 loss: 0.433\n",
            "270 에포크 정확도: 0.842\n",
            "271 에포크 loss: 0.417\n",
            "271 에포크 정확도: 0.851\n",
            "272 에포크 loss: 0.405\n",
            "272 에포크 정확도: 0.844\n",
            "273 에포크 loss: 0.441\n",
            "273 에포크 정확도: 0.846\n",
            "274 에포크 loss: 0.465\n",
            "274 에포크 정확도: 0.833\n",
            "275 에포크 loss: 0.448\n",
            "275 에포크 정확도: 0.833\n",
            "276 에포크 loss: 0.433\n",
            "276 에포크 정확도: 0.846\n",
            "277 에포크 loss: 0.458\n",
            "277 에포크 정확도: 0.833\n",
            "278 에포크 loss: 0.468\n",
            "278 에포크 정확도: 0.827\n",
            "279 에포크 loss: 0.424\n",
            "279 에포크 정확도: 0.843\n",
            "280 에포크 loss: 0.435\n",
            "280 에포크 정확도: 0.843\n",
            "281 에포크 loss: 0.429\n",
            "281 에포크 정확도: 0.842\n",
            "282 에포크 loss: 0.462\n",
            "282 에포크 정확도: 0.837\n",
            "283 에포크 loss: 0.446\n",
            "283 에포크 정확도: 0.846\n",
            "284 에포크 loss: 0.447\n",
            "284 에포크 정확도: 0.831\n",
            "285 에포크 loss: 0.425\n",
            "285 에포크 정확도: 0.852\n",
            "286 에포크 loss: 0.427\n",
            "286 에포크 정확도: 0.848\n",
            "287 에포크 loss: 0.437\n",
            "287 에포크 정확도: 0.844\n",
            "288 에포크 loss: 0.394\n",
            "288 에포크 정확도: 0.859\n",
            "289 에포크 loss: 0.442\n",
            "289 에포크 정확도: 0.840\n",
            "290 에포크 loss: 0.425\n",
            "290 에포크 정확도: 0.847\n",
            "291 에포크 loss: 0.436\n",
            "291 에포크 정확도: 0.841\n",
            "292 에포크 loss: 0.426\n",
            "292 에포크 정확도: 0.843\n",
            "293 에포크 loss: 0.460\n",
            "293 에포크 정확도: 0.844\n",
            "294 에포크 loss: 0.435\n",
            "294 에포크 정확도: 0.837\n",
            "295 에포크 loss: 0.444\n",
            "295 에포크 정확도: 0.836\n",
            "296 에포크 loss: 0.444\n",
            "296 에포크 정확도: 0.836\n",
            "297 에포크 loss: 0.442\n",
            "297 에포크 정확도: 0.841\n",
            "298 에포크 loss: 0.410\n",
            "298 에포크 정확도: 0.857\n",
            "299 에포크 loss: 0.436\n",
            "299 에포크 정확도: 0.835\n",
            "300 에포크 loss: 0.421\n",
            "300 에포크 정확도: 0.848\n",
            "301 에포크 loss: 0.420\n",
            "301 에포크 정확도: 0.846\n",
            "302 에포크 loss: 0.446\n",
            "302 에포크 정확도: 0.842\n",
            "303 에포크 loss: 0.426\n",
            "303 에포크 정확도: 0.852\n",
            "304 에포크 loss: 0.437\n",
            "304 에포크 정확도: 0.834\n",
            "305 에포크 loss: 0.404\n",
            "305 에포크 정확도: 0.855\n",
            "306 에포크 loss: 0.435\n",
            "306 에포크 정확도: 0.844\n",
            "307 에포크 loss: 0.428\n",
            "307 에포크 정확도: 0.843\n",
            "308 에포크 loss: 0.446\n",
            "308 에포크 정확도: 0.844\n",
            "309 에포크 loss: 0.430\n",
            "309 에포크 정확도: 0.854\n",
            "310 에포크 loss: 0.429\n",
            "310 에포크 정확도: 0.851\n",
            "311 에포크 loss: 0.432\n",
            "311 에포크 정확도: 0.844\n",
            "312 에포크 loss: 0.414\n",
            "312 에포크 정확도: 0.845\n",
            "313 에포크 loss: 0.418\n",
            "313 에포크 정확도: 0.849\n",
            "314 에포크 loss: 0.418\n",
            "314 에포크 정확도: 0.856\n",
            "315 에포크 loss: 0.447\n",
            "315 에포크 정확도: 0.842\n",
            "316 에포크 loss: 0.433\n",
            "316 에포크 정확도: 0.845\n",
            "317 에포크 loss: 0.428\n",
            "317 에포크 정확도: 0.846\n",
            "318 에포크 loss: 0.391\n",
            "318 에포크 정확도: 0.859\n",
            "319 에포크 loss: 0.429\n",
            "319 에포크 정확도: 0.853\n",
            "320 에포크 loss: 0.441\n",
            "320 에포크 정확도: 0.837\n",
            "321 에포크 loss: 0.446\n",
            "321 에포크 정확도: 0.838\n",
            "322 에포크 loss: 0.421\n",
            "322 에포크 정확도: 0.837\n",
            "323 에포크 loss: 0.401\n",
            "323 에포크 정확도: 0.860\n",
            "324 에포크 loss: 0.446\n",
            "324 에포크 정확도: 0.840\n",
            "325 에포크 loss: 0.459\n",
            "325 에포크 정확도: 0.839\n",
            "326 에포크 loss: 0.417\n",
            "326 에포크 정확도: 0.853\n",
            "327 에포크 loss: 0.415\n",
            "327 에포크 정확도: 0.859\n",
            "328 에포크 loss: 0.414\n",
            "328 에포크 정확도: 0.850\n",
            "329 에포크 loss: 0.419\n",
            "329 에포크 정확도: 0.846\n",
            "330 에포크 loss: 0.421\n",
            "330 에포크 정확도: 0.847\n",
            "331 에포크 loss: 0.404\n",
            "331 에포크 정확도: 0.852\n",
            "332 에포크 loss: 0.428\n",
            "332 에포크 정확도: 0.848\n",
            "333 에포크 loss: 0.436\n",
            "333 에포크 정확도: 0.840\n",
            "334 에포크 loss: 0.440\n",
            "334 에포크 정확도: 0.843\n",
            "335 에포크 loss: 0.442\n",
            "335 에포크 정확도: 0.841\n",
            "336 에포크 loss: 0.405\n",
            "336 에포크 정확도: 0.848\n",
            "337 에포크 loss: 0.426\n",
            "337 에포크 정확도: 0.850\n",
            "338 에포크 loss: 0.443\n",
            "338 에포크 정확도: 0.838\n",
            "339 에포크 loss: 0.421\n",
            "339 에포크 정확도: 0.849\n",
            "340 에포크 loss: 0.416\n",
            "340 에포크 정확도: 0.861\n",
            "341 에포크 loss: 0.416\n",
            "341 에포크 정확도: 0.858\n",
            "342 에포크 loss: 0.413\n",
            "342 에포크 정확도: 0.859\n",
            "343 에포크 loss: 0.418\n",
            "343 에포크 정확도: 0.856\n",
            "344 에포크 loss: 0.420\n",
            "344 에포크 정확도: 0.850\n",
            "345 에포크 loss: 0.414\n",
            "345 에포크 정확도: 0.853\n",
            "346 에포크 loss: 0.431\n",
            "346 에포크 정확도: 0.851\n",
            "347 에포크 loss: 0.430\n",
            "347 에포크 정확도: 0.847\n",
            "348 에포크 loss: 0.439\n",
            "348 에포크 정확도: 0.846\n",
            "349 에포크 loss: 0.420\n",
            "349 에포크 정확도: 0.847\n",
            "350 에포크 loss: 0.419\n",
            "350 에포크 정확도: 0.847\n",
            "351 에포크 loss: 0.394\n",
            "351 에포크 정확도: 0.865\n",
            "352 에포크 loss: 0.405\n",
            "352 에포크 정확도: 0.857\n",
            "353 에포크 loss: 0.406\n",
            "353 에포크 정확도: 0.856\n",
            "354 에포크 loss: 0.427\n",
            "354 에포크 정확도: 0.845\n",
            "355 에포크 loss: 0.405\n",
            "355 에포크 정확도: 0.855\n",
            "356 에포크 loss: 0.414\n",
            "356 에포크 정확도: 0.855\n",
            "357 에포크 loss: 0.431\n",
            "357 에포크 정확도: 0.844\n",
            "358 에포크 loss: 0.441\n",
            "358 에포크 정확도: 0.853\n",
            "359 에포크 loss: 0.424\n",
            "359 에포크 정확도: 0.845\n",
            "360 에포크 loss: 0.437\n",
            "360 에포크 정확도: 0.843\n",
            "361 에포크 loss: 0.405\n",
            "361 에포크 정확도: 0.846\n",
            "362 에포크 loss: 0.451\n",
            "362 에포크 정확도: 0.840\n",
            "363 에포크 loss: 0.402\n",
            "363 에포크 정확도: 0.851\n",
            "364 에포크 loss: 0.419\n",
            "364 에포크 정확도: 0.851\n",
            "365 에포크 loss: 0.394\n",
            "365 에포크 정확도: 0.860\n",
            "366 에포크 loss: 0.413\n",
            "366 에포크 정확도: 0.841\n",
            "367 에포크 loss: 0.403\n",
            "367 에포크 정확도: 0.859\n",
            "368 에포크 loss: 0.430\n",
            "368 에포크 정확도: 0.847\n",
            "369 에포크 loss: 0.432\n",
            "369 에포크 정확도: 0.849\n",
            "370 에포크 loss: 0.408\n",
            "370 에포크 정확도: 0.851\n",
            "371 에포크 loss: 0.419\n",
            "371 에포크 정확도: 0.857\n",
            "372 에포크 loss: 0.410\n",
            "372 에포크 정확도: 0.853\n",
            "373 에포크 loss: 0.404\n",
            "373 에포크 정확도: 0.860\n",
            "374 에포크 loss: 0.396\n",
            "374 에포크 정확도: 0.858\n",
            "375 에포크 loss: 0.422\n",
            "375 에포크 정확도: 0.847\n",
            "376 에포크 loss: 0.451\n",
            "376 에포크 정확도: 0.841\n",
            "377 에포크 loss: 0.415\n",
            "377 에포크 정확도: 0.853\n",
            "378 에포크 loss: 0.407\n",
            "378 에포크 정확도: 0.848\n",
            "379 에포크 loss: 0.416\n",
            "379 에포크 정확도: 0.847\n",
            "380 에포크 loss: 0.394\n",
            "380 에포크 정확도: 0.859\n",
            "381 에포크 loss: 0.451\n",
            "381 에포크 정확도: 0.836\n",
            "382 에포크 loss: 0.429\n",
            "382 에포크 정확도: 0.856\n",
            "383 에포크 loss: 0.406\n",
            "383 에포크 정확도: 0.858\n",
            "384 에포크 loss: 0.410\n",
            "384 에포크 정확도: 0.857\n",
            "385 에포크 loss: 0.418\n",
            "385 에포크 정확도: 0.856\n",
            "386 에포크 loss: 0.390\n",
            "386 에포크 정확도: 0.856\n",
            "387 에포크 loss: 0.416\n",
            "387 에포크 정확도: 0.849\n",
            "388 에포크 loss: 0.440\n",
            "388 에포크 정확도: 0.840\n",
            "389 에포크 loss: 0.409\n",
            "389 에포크 정확도: 0.854\n",
            "390 에포크 loss: 0.429\n",
            "390 에포크 정확도: 0.838\n",
            "391 에포크 loss: 0.401\n",
            "391 에포크 정확도: 0.855\n",
            "392 에포크 loss: 0.403\n",
            "392 에포크 정확도: 0.863\n",
            "393 에포크 loss: 0.452\n",
            "393 에포크 정확도: 0.847\n",
            "394 에포크 loss: 0.432\n",
            "394 에포크 정확도: 0.848\n",
            "395 에포크 loss: 0.406\n",
            "395 에포크 정확도: 0.860\n",
            "396 에포크 loss: 0.400\n",
            "396 에포크 정확도: 0.851\n",
            "397 에포크 loss: 0.403\n",
            "397 에포크 정확도: 0.866\n",
            "398 에포크 loss: 0.382\n",
            "398 에포크 정확도: 0.863\n",
            "399 에포크 loss: 0.427\n",
            "399 에포크 정확도: 0.845\n",
            "400 에포크 loss: 0.408\n",
            "400 에포크 정확도: 0.853\n",
            "401 에포크 loss: 0.415\n",
            "401 에포크 정확도: 0.851\n",
            "402 에포크 loss: 0.415\n",
            "402 에포크 정확도: 0.852\n",
            "403 에포크 loss: 0.396\n",
            "403 에포크 정확도: 0.866\n",
            "404 에포크 loss: 0.379\n",
            "404 에포크 정확도: 0.863\n",
            "405 에포크 loss: 0.411\n",
            "405 에포크 정확도: 0.854\n",
            "406 에포크 loss: 0.441\n",
            "406 에포크 정확도: 0.843\n",
            "407 에포크 loss: 0.414\n",
            "407 에포크 정확도: 0.852\n",
            "408 에포크 loss: 0.417\n",
            "408 에포크 정확도: 0.848\n",
            "409 에포크 loss: 0.412\n",
            "409 에포크 정확도: 0.853\n",
            "410 에포크 loss: 0.387\n",
            "410 에포크 정확도: 0.867\n",
            "411 에포크 loss: 0.414\n",
            "411 에포크 정확도: 0.854\n",
            "412 에포크 loss: 0.408\n",
            "412 에포크 정확도: 0.851\n",
            "413 에포크 loss: 0.410\n",
            "413 에포크 정확도: 0.862\n",
            "414 에포크 loss: 0.407\n",
            "414 에포크 정확도: 0.853\n",
            "415 에포크 loss: 0.434\n",
            "415 에포크 정확도: 0.850\n",
            "416 에포크 loss: 0.411\n",
            "416 에포크 정확도: 0.854\n",
            "417 에포크 loss: 0.423\n",
            "417 에포크 정확도: 0.850\n",
            "418 에포크 loss: 0.411\n",
            "418 에포크 정확도: 0.858\n",
            "419 에포크 loss: 0.420\n",
            "419 에포크 정확도: 0.851\n",
            "420 에포크 loss: 0.388\n",
            "420 에포크 정확도: 0.864\n",
            "421 에포크 loss: 0.430\n",
            "421 에포크 정확도: 0.841\n",
            "422 에포크 loss: 0.420\n",
            "422 에포크 정확도: 0.851\n",
            "423 에포크 loss: 0.402\n",
            "423 에포크 정확도: 0.855\n",
            "424 에포크 loss: 0.445\n",
            "424 에포크 정확도: 0.839\n",
            "425 에포크 loss: 0.421\n",
            "425 에포크 정확도: 0.852\n",
            "426 에포크 loss: 0.425\n",
            "426 에포크 정확도: 0.862\n",
            "427 에포크 loss: 0.426\n",
            "427 에포크 정확도: 0.857\n",
            "428 에포크 loss: 0.387\n",
            "428 에포크 정확도: 0.859\n",
            "429 에포크 loss: 0.402\n",
            "429 에포크 정확도: 0.858\n",
            "430 에포크 loss: 0.400\n",
            "430 에포크 정확도: 0.859\n",
            "431 에포크 loss: 0.429\n",
            "431 에포크 정확도: 0.848\n",
            "432 에포크 loss: 0.411\n",
            "432 에포크 정확도: 0.854\n",
            "433 에포크 loss: 0.388\n",
            "433 에포크 정확도: 0.862\n",
            "434 에포크 loss: 0.414\n",
            "434 에포크 정확도: 0.853\n",
            "435 에포크 loss: 0.438\n",
            "435 에포크 정확도: 0.849\n",
            "436 에포크 loss: 0.404\n",
            "436 에포크 정확도: 0.858\n",
            "437 에포크 loss: 0.416\n",
            "437 에포크 정확도: 0.868\n",
            "438 에포크 loss: 0.403\n",
            "438 에포크 정확도: 0.861\n",
            "439 에포크 loss: 0.407\n",
            "439 에포크 정확도: 0.856\n",
            "440 에포크 loss: 0.423\n",
            "440 에포크 정확도: 0.849\n",
            "441 에포크 loss: 0.396\n",
            "441 에포크 정확도: 0.859\n",
            "442 에포크 loss: 0.391\n",
            "442 에포크 정확도: 0.864\n",
            "443 에포크 loss: 0.405\n",
            "443 에포크 정확도: 0.855\n",
            "444 에포크 loss: 0.444\n",
            "444 에포크 정확도: 0.851\n",
            "445 에포크 loss: 0.398\n",
            "445 에포크 정확도: 0.866\n",
            "446 에포크 loss: 0.369\n",
            "446 에포크 정확도: 0.872\n",
            "447 에포크 loss: 0.399\n",
            "447 에포크 정확도: 0.849\n",
            "448 에포크 loss: 0.397\n",
            "448 에포크 정확도: 0.855\n",
            "449 에포크 loss: 0.373\n",
            "449 에포크 정확도: 0.873\n",
            "450 에포크 loss: 0.440\n",
            "450 에포크 정확도: 0.842\n",
            "451 에포크 loss: 0.366\n",
            "451 에포크 정확도: 0.863\n",
            "452 에포크 loss: 0.391\n",
            "452 에포크 정확도: 0.861\n",
            "453 에포크 loss: 0.429\n",
            "453 에포크 정확도: 0.848\n",
            "454 에포크 loss: 0.399\n",
            "454 에포크 정확도: 0.851\n",
            "455 에포크 loss: 0.383\n",
            "455 에포크 정확도: 0.868\n",
            "456 에포크 loss: 0.402\n",
            "456 에포크 정확도: 0.852\n",
            "457 에포크 loss: 0.421\n",
            "457 에포크 정확도: 0.844\n",
            "458 에포크 loss: 0.385\n",
            "458 에포크 정확도: 0.867\n",
            "459 에포크 loss: 0.405\n",
            "459 에포크 정확도: 0.852\n",
            "460 에포크 loss: 0.403\n",
            "460 에포크 정확도: 0.859\n",
            "461 에포크 loss: 0.388\n",
            "461 에포크 정확도: 0.864\n",
            "462 에포크 loss: 0.411\n",
            "462 에포크 정확도: 0.848\n",
            "463 에포크 loss: 0.388\n",
            "463 에포크 정확도: 0.860\n",
            "464 에포크 loss: 0.421\n",
            "464 에포크 정확도: 0.853\n",
            "465 에포크 loss: 0.405\n",
            "465 에포크 정확도: 0.851\n",
            "466 에포크 loss: 0.393\n",
            "466 에포크 정확도: 0.865\n",
            "467 에포크 loss: 0.429\n",
            "467 에포크 정확도: 0.850\n",
            "468 에포크 loss: 0.418\n",
            "468 에포크 정확도: 0.849\n",
            "469 에포크 loss: 0.423\n",
            "469 에포크 정확도: 0.850\n",
            "470 에포크 loss: 0.383\n",
            "470 에포크 정확도: 0.864\n",
            "471 에포크 loss: 0.428\n",
            "471 에포크 정확도: 0.850\n",
            "472 에포크 loss: 0.373\n",
            "472 에포크 정확도: 0.861\n",
            "473 에포크 loss: 0.404\n",
            "473 에포크 정확도: 0.856\n",
            "474 에포크 loss: 0.412\n",
            "474 에포크 정확도: 0.850\n",
            "475 에포크 loss: 0.393\n",
            "475 에포크 정확도: 0.857\n",
            "476 에포크 loss: 0.410\n",
            "476 에포크 정확도: 0.857\n",
            "477 에포크 loss: 0.405\n",
            "477 에포크 정확도: 0.866\n",
            "478 에포크 loss: 0.370\n",
            "478 에포크 정확도: 0.869\n",
            "479 에포크 loss: 0.395\n",
            "479 에포크 정확도: 0.860\n",
            "480 에포크 loss: 0.399\n",
            "480 에포크 정확도: 0.859\n",
            "481 에포크 loss: 0.407\n",
            "481 에포크 정확도: 0.861\n",
            "482 에포크 loss: 0.423\n",
            "482 에포크 정확도: 0.854\n",
            "483 에포크 loss: 0.399\n",
            "483 에포크 정확도: 0.853\n",
            "484 에포크 loss: 0.411\n",
            "484 에포크 정확도: 0.855\n",
            "485 에포크 loss: 0.423\n",
            "485 에포크 정확도: 0.848\n",
            "486 에포크 loss: 0.412\n",
            "486 에포크 정확도: 0.853\n",
            "487 에포크 loss: 0.389\n",
            "487 에포크 정확도: 0.863\n",
            "488 에포크 loss: 0.415\n",
            "488 에포크 정확도: 0.850\n",
            "489 에포크 loss: 0.395\n",
            "489 에포크 정확도: 0.862\n",
            "490 에포크 loss: 0.408\n",
            "490 에포크 정확도: 0.851\n",
            "491 에포크 loss: 0.373\n",
            "491 에포크 정확도: 0.869\n",
            "492 에포크 loss: 0.400\n",
            "492 에포크 정확도: 0.852\n",
            "493 에포크 loss: 0.412\n",
            "493 에포크 정확도: 0.854\n",
            "494 에포크 loss: 0.385\n",
            "494 에포크 정확도: 0.859\n",
            "495 에포크 loss: 0.419\n",
            "495 에포크 정확도: 0.855\n",
            "496 에포크 loss: 0.419\n",
            "496 에포크 정확도: 0.853\n",
            "497 에포크 loss: 0.386\n",
            "497 에포크 정확도: 0.869\n",
            "498 에포크 loss: 0.388\n",
            "498 에포크 정확도: 0.856\n",
            "499 에포크 loss: 0.401\n",
            "499 에포크 정확도: 0.858\n",
            "500 에포크 loss: 0.413\n",
            "500 에포크 정확도: 0.853\n",
            "501 에포크 loss: 0.380\n",
            "501 에포크 정확도: 0.865\n",
            "502 에포크 loss: 0.383\n",
            "502 에포크 정확도: 0.866\n",
            "503 에포크 loss: 0.392\n",
            "503 에포크 정확도: 0.867\n",
            "504 에포크 loss: 0.420\n",
            "504 에포크 정확도: 0.857\n",
            "505 에포크 loss: 0.411\n",
            "505 에포크 정확도: 0.859\n",
            "506 에포크 loss: 0.407\n",
            "506 에포크 정확도: 0.859\n",
            "507 에포크 loss: 0.388\n",
            "507 에포크 정확도: 0.859\n",
            "508 에포크 loss: 0.378\n",
            "508 에포크 정확도: 0.867\n",
            "509 에포크 loss: 0.424\n",
            "509 에포크 정확도: 0.841\n",
            "510 에포크 loss: 0.391\n",
            "510 에포크 정확도: 0.856\n",
            "511 에포크 loss: 0.391\n",
            "511 에포크 정확도: 0.858\n",
            "512 에포크 loss: 0.390\n",
            "512 에포크 정확도: 0.860\n",
            "513 에포크 loss: 0.377\n",
            "513 에포크 정확도: 0.869\n",
            "514 에포크 loss: 0.398\n",
            "514 에포크 정확도: 0.854\n",
            "515 에포크 loss: 0.381\n",
            "515 에포크 정확도: 0.863\n",
            "516 에포크 loss: 0.408\n",
            "516 에포크 정확도: 0.853\n",
            "517 에포크 loss: 0.406\n",
            "517 에포크 정확도: 0.851\n",
            "518 에포크 loss: 0.403\n",
            "518 에포크 정확도: 0.856\n",
            "519 에포크 loss: 0.391\n",
            "519 에포크 정확도: 0.851\n",
            "520 에포크 loss: 0.403\n",
            "520 에포크 정확도: 0.863\n",
            "521 에포크 loss: 0.413\n",
            "521 에포크 정확도: 0.847\n",
            "522 에포크 loss: 0.401\n",
            "522 에포크 정확도: 0.849\n",
            "523 에포크 loss: 0.396\n",
            "523 에포크 정확도: 0.856\n",
            "524 에포크 loss: 0.409\n",
            "524 에포크 정확도: 0.859\n",
            "525 에포크 loss: 0.402\n",
            "525 에포크 정확도: 0.855\n",
            "526 에포크 loss: 0.396\n",
            "526 에포크 정확도: 0.856\n",
            "527 에포크 loss: 0.379\n",
            "527 에포크 정확도: 0.868\n",
            "528 에포크 loss: 0.403\n",
            "528 에포크 정확도: 0.856\n",
            "529 에포크 loss: 0.392\n",
            "529 에포크 정확도: 0.857\n",
            "530 에포크 loss: 0.418\n",
            "530 에포크 정확도: 0.847\n",
            "531 에포크 loss: 0.401\n",
            "531 에포크 정확도: 0.857\n",
            "532 에포크 loss: 0.401\n",
            "532 에포크 정확도: 0.857\n",
            "533 에포크 loss: 0.414\n",
            "533 에포크 정확도: 0.855\n",
            "534 에포크 loss: 0.370\n",
            "534 에포크 정확도: 0.867\n",
            "535 에포크 loss: 0.394\n",
            "535 에포크 정확도: 0.855\n",
            "536 에포크 loss: 0.383\n",
            "536 에포크 정확도: 0.865\n",
            "537 에포크 loss: 0.412\n",
            "537 에포크 정확도: 0.847\n",
            "538 에포크 loss: 0.373\n",
            "538 에포크 정확도: 0.875\n",
            "539 에포크 loss: 0.382\n",
            "539 에포크 정확도: 0.858\n",
            "540 에포크 loss: 0.389\n",
            "540 에포크 정확도: 0.857\n",
            "541 에포크 loss: 0.387\n",
            "541 에포크 정확도: 0.865\n",
            "542 에포크 loss: 0.428\n",
            "542 에포크 정확도: 0.849\n",
            "543 에포크 loss: 0.395\n",
            "543 에포크 정확도: 0.862\n",
            "544 에포크 loss: 0.388\n",
            "544 에포크 정확도: 0.853\n",
            "545 에포크 loss: 0.395\n",
            "545 에포크 정확도: 0.853\n",
            "546 에포크 loss: 0.377\n",
            "546 에포크 정확도: 0.861\n",
            "547 에포크 loss: 0.422\n",
            "547 에포크 정확도: 0.845\n",
            "548 에포크 loss: 0.412\n",
            "548 에포크 정확도: 0.853\n",
            "549 에포크 loss: 0.406\n",
            "549 에포크 정확도: 0.864\n",
            "550 에포크 loss: 0.403\n",
            "550 에포크 정확도: 0.857\n",
            "551 에포크 loss: 0.414\n",
            "551 에포크 정확도: 0.858\n",
            "552 에포크 loss: 0.400\n",
            "552 에포크 정확도: 0.866\n",
            "553 에포크 loss: 0.395\n",
            "553 에포크 정확도: 0.857\n",
            "554 에포크 loss: 0.372\n",
            "554 에포크 정확도: 0.868\n",
            "555 에포크 loss: 0.392\n",
            "555 에포크 정확도: 0.860\n",
            "556 에포크 loss: 0.381\n",
            "556 에포크 정확도: 0.870\n",
            "557 에포크 loss: 0.367\n",
            "557 에포크 정확도: 0.881\n",
            "558 에포크 loss: 0.407\n",
            "558 에포크 정확도: 0.857\n",
            "559 에포크 loss: 0.373\n",
            "559 에포크 정확도: 0.860\n",
            "560 에포크 loss: 0.399\n",
            "560 에포크 정확도: 0.859\n",
            "561 에포크 loss: 0.380\n",
            "561 에포크 정확도: 0.869\n",
            "562 에포크 loss: 0.405\n",
            "562 에포크 정확도: 0.859\n",
            "563 에포크 loss: 0.404\n",
            "563 에포크 정확도: 0.856\n",
            "564 에포크 loss: 0.399\n",
            "564 에포크 정확도: 0.861\n",
            "565 에포크 loss: 0.405\n",
            "565 에포크 정확도: 0.854\n",
            "566 에포크 loss: 0.408\n",
            "566 에포크 정확도: 0.851\n",
            "567 에포크 loss: 0.377\n",
            "567 에포크 정확도: 0.859\n",
            "568 에포크 loss: 0.414\n",
            "568 에포크 정확도: 0.846\n",
            "569 에포크 loss: 0.412\n",
            "569 에포크 정확도: 0.852\n",
            "570 에포크 loss: 0.400\n",
            "570 에포크 정확도: 0.849\n",
            "571 에포크 loss: 0.378\n",
            "571 에포크 정확도: 0.866\n",
            "572 에포크 loss: 0.366\n",
            "572 에포크 정확도: 0.873\n",
            "573 에포크 loss: 0.368\n",
            "573 에포크 정확도: 0.874\n",
            "574 에포크 loss: 0.400\n",
            "574 에포크 정확도: 0.846\n",
            "575 에포크 loss: 0.364\n",
            "575 에포크 정확도: 0.869\n",
            "576 에포크 loss: 0.409\n",
            "576 에포크 정확도: 0.861\n",
            "577 에포크 loss: 0.383\n",
            "577 에포크 정확도: 0.870\n",
            "578 에포크 loss: 0.380\n",
            "578 에포크 정확도: 0.867\n",
            "579 에포크 loss: 0.389\n",
            "579 에포크 정확도: 0.861\n",
            "580 에포크 loss: 0.368\n",
            "580 에포크 정확도: 0.873\n",
            "581 에포크 loss: 0.375\n",
            "581 에포크 정확도: 0.869\n",
            "582 에포크 loss: 0.393\n",
            "582 에포크 정확도: 0.859\n",
            "583 에포크 loss: 0.389\n",
            "583 에포크 정확도: 0.864\n",
            "584 에포크 loss: 0.386\n",
            "584 에포크 정확도: 0.866\n",
            "585 에포크 loss: 0.392\n",
            "585 에포크 정확도: 0.857\n",
            "586 에포크 loss: 0.380\n",
            "586 에포크 정확도: 0.867\n",
            "587 에포크 loss: 0.378\n",
            "587 에포크 정확도: 0.863\n",
            "588 에포크 loss: 0.383\n",
            "588 에포크 정확도: 0.866\n",
            "589 에포크 loss: 0.414\n",
            "589 에포크 정확도: 0.859\n",
            "590 에포크 loss: 0.388\n",
            "590 에포크 정확도: 0.863\n",
            "591 에포크 loss: 0.366\n",
            "591 에포크 정확도: 0.866\n",
            "592 에포크 loss: 0.413\n",
            "592 에포크 정확도: 0.853\n",
            "593 에포크 loss: 0.390\n",
            "593 에포크 정확도: 0.861\n",
            "594 에포크 loss: 0.387\n",
            "594 에포크 정확도: 0.866\n",
            "595 에포크 loss: 0.371\n",
            "595 에포크 정확도: 0.868\n",
            "596 에포크 loss: 0.385\n",
            "596 에포크 정확도: 0.863\n",
            "597 에포크 loss: 0.404\n",
            "597 에포크 정확도: 0.854\n",
            "598 에포크 loss: 0.381\n",
            "598 에포크 정확도: 0.866\n",
            "599 에포크 loss: 0.373\n",
            "599 에포크 정확도: 0.867\n",
            "600 에포크 loss: 0.380\n",
            "600 에포크 정확도: 0.867\n",
            "601 에포크 loss: 0.383\n",
            "601 에포크 정확도: 0.861\n",
            "602 에포크 loss: 0.396\n",
            "602 에포크 정확도: 0.852\n",
            "603 에포크 loss: 0.407\n",
            "603 에포크 정확도: 0.859\n",
            "604 에포크 loss: 0.377\n",
            "604 에포크 정확도: 0.866\n",
            "605 에포크 loss: 0.390\n",
            "605 에포크 정확도: 0.861\n",
            "606 에포크 loss: 0.390\n",
            "606 에포크 정확도: 0.860\n",
            "607 에포크 loss: 0.407\n",
            "607 에포크 정확도: 0.859\n",
            "608 에포크 loss: 0.365\n",
            "608 에포크 정확도: 0.863\n",
            "609 에포크 loss: 0.400\n",
            "609 에포크 정확도: 0.853\n",
            "610 에포크 loss: 0.399\n",
            "610 에포크 정확도: 0.862\n",
            "611 에포크 loss: 0.401\n",
            "611 에포크 정확도: 0.864\n",
            "612 에포크 loss: 0.404\n",
            "612 에포크 정확도: 0.863\n",
            "613 에포크 loss: 0.383\n",
            "613 에포크 정확도: 0.867\n",
            "614 에포크 loss: 0.384\n",
            "614 에포크 정확도: 0.865\n",
            "615 에포크 loss: 0.407\n",
            "615 에포크 정확도: 0.856\n",
            "616 에포크 loss: 0.392\n",
            "616 에포크 정확도: 0.861\n",
            "617 에포크 loss: 0.364\n",
            "617 에포크 정확도: 0.875\n",
            "618 에포크 loss: 0.389\n",
            "618 에포크 정확도: 0.863\n",
            "619 에포크 loss: 0.403\n",
            "619 에포크 정확도: 0.848\n",
            "620 에포크 loss: 0.406\n",
            "620 에포크 정확도: 0.859\n",
            "621 에포크 loss: 0.406\n",
            "621 에포크 정확도: 0.861\n",
            "622 에포크 loss: 0.380\n",
            "622 에포크 정확도: 0.858\n",
            "623 에포크 loss: 0.420\n",
            "623 에포크 정확도: 0.853\n",
            "624 에포크 loss: 0.394\n",
            "624 에포크 정확도: 0.855\n",
            "625 에포크 loss: 0.401\n",
            "625 에포크 정확도: 0.866\n",
            "626 에포크 loss: 0.390\n",
            "626 에포크 정확도: 0.869\n",
            "627 에포크 loss: 0.400\n",
            "627 에포크 정확도: 0.849\n",
            "628 에포크 loss: 0.422\n",
            "628 에포크 정확도: 0.851\n",
            "629 에포크 loss: 0.363\n",
            "629 에포크 정확도: 0.867\n",
            "630 에포크 loss: 0.394\n",
            "630 에포크 정확도: 0.864\n",
            "631 에포크 loss: 0.381\n",
            "631 에포크 정확도: 0.859\n",
            "632 에포크 loss: 0.371\n",
            "632 에포크 정확도: 0.861\n",
            "633 에포크 loss: 0.389\n",
            "633 에포크 정확도: 0.862\n",
            "634 에포크 loss: 0.385\n",
            "634 에포크 정확도: 0.859\n",
            "635 에포크 loss: 0.389\n",
            "635 에포크 정확도: 0.859\n",
            "636 에포크 loss: 0.397\n",
            "636 에포크 정확도: 0.862\n",
            "637 에포크 loss: 0.430\n",
            "637 에포크 정확도: 0.849\n",
            "638 에포크 loss: 0.383\n",
            "638 에포크 정확도: 0.858\n",
            "639 에포크 loss: 0.385\n",
            "639 에포크 정확도: 0.867\n",
            "640 에포크 loss: 0.424\n",
            "640 에포크 정확도: 0.849\n",
            "641 에포크 loss: 0.401\n",
            "641 에포크 정확도: 0.853\n",
            "642 에포크 loss: 0.389\n",
            "642 에포크 정확도: 0.856\n",
            "643 에포크 loss: 0.374\n",
            "643 에포크 정확도: 0.862\n",
            "644 에포크 loss: 0.400\n",
            "644 에포크 정확도: 0.853\n",
            "645 에포크 loss: 0.376\n",
            "645 에포크 정확도: 0.870\n",
            "646 에포크 loss: 0.385\n",
            "646 에포크 정확도: 0.868\n",
            "647 에포크 loss: 0.391\n",
            "647 에포크 정확도: 0.867\n",
            "648 에포크 loss: 0.388\n",
            "648 에포크 정확도: 0.863\n",
            "649 에포크 loss: 0.381\n",
            "649 에포크 정확도: 0.874\n",
            "650 에포크 loss: 0.372\n",
            "650 에포크 정확도: 0.873\n",
            "651 에포크 loss: 0.355\n",
            "651 에포크 정확도: 0.876\n",
            "652 에포크 loss: 0.381\n",
            "652 에포크 정확도: 0.868\n",
            "653 에포크 loss: 0.360\n",
            "653 에포크 정확도: 0.874\n",
            "654 에포크 loss: 0.381\n",
            "654 에포크 정확도: 0.868\n",
            "655 에포크 loss: 0.394\n",
            "655 에포크 정확도: 0.865\n",
            "656 에포크 loss: 0.401\n",
            "656 에포크 정확도: 0.865\n",
            "657 에포크 loss: 0.377\n",
            "657 에포크 정확도: 0.863\n",
            "658 에포크 loss: 0.364\n",
            "658 에포크 정확도: 0.869\n",
            "659 에포크 loss: 0.376\n",
            "659 에포크 정확도: 0.865\n",
            "660 에포크 loss: 0.392\n",
            "660 에포크 정확도: 0.858\n",
            "661 에포크 loss: 0.367\n",
            "661 에포크 정확도: 0.873\n",
            "662 에포크 loss: 0.397\n",
            "662 에포크 정확도: 0.862\n",
            "663 에포크 loss: 0.396\n",
            "663 에포크 정확도: 0.863\n",
            "664 에포크 loss: 0.415\n",
            "664 에포크 정확도: 0.855\n",
            "665 에포크 loss: 0.403\n",
            "665 에포크 정확도: 0.863\n",
            "666 에포크 loss: 0.377\n",
            "666 에포크 정확도: 0.855\n",
            "667 에포크 loss: 0.386\n",
            "667 에포크 정확도: 0.862\n",
            "668 에포크 loss: 0.374\n",
            "668 에포크 정확도: 0.870\n",
            "669 에포크 loss: 0.383\n",
            "669 에포크 정확도: 0.868\n",
            "670 에포크 loss: 0.367\n",
            "670 에포크 정확도: 0.866\n",
            "671 에포크 loss: 0.346\n",
            "671 에포크 정확도: 0.872\n",
            "672 에포크 loss: 0.389\n",
            "672 에포크 정확도: 0.858\n",
            "673 에포크 loss: 0.393\n",
            "673 에포크 정확도: 0.855\n",
            "674 에포크 loss: 0.393\n",
            "674 에포크 정확도: 0.859\n",
            "675 에포크 loss: 0.374\n",
            "675 에포크 정확도: 0.864\n",
            "676 에포크 loss: 0.373\n",
            "676 에포크 정확도: 0.861\n",
            "677 에포크 loss: 0.390\n",
            "677 에포크 정확도: 0.864\n",
            "678 에포크 loss: 0.373\n",
            "678 에포크 정확도: 0.866\n",
            "679 에포크 loss: 0.384\n",
            "679 에포크 정확도: 0.863\n",
            "680 에포크 loss: 0.375\n",
            "680 에포크 정확도: 0.865\n",
            "681 에포크 loss: 0.391\n",
            "681 에포크 정확도: 0.860\n",
            "682 에포크 loss: 0.378\n",
            "682 에포크 정확도: 0.869\n",
            "683 에포크 loss: 0.384\n",
            "683 에포크 정확도: 0.867\n",
            "684 에포크 loss: 0.397\n",
            "684 에포크 정확도: 0.853\n",
            "685 에포크 loss: 0.381\n",
            "685 에포크 정확도: 0.860\n",
            "686 에포크 loss: 0.411\n",
            "686 에포크 정확도: 0.856\n",
            "687 에포크 loss: 0.371\n",
            "687 에포크 정확도: 0.866\n",
            "688 에포크 loss: 0.386\n",
            "688 에포크 정확도: 0.866\n",
            "689 에포크 loss: 0.404\n",
            "689 에포크 정확도: 0.863\n",
            "690 에포크 loss: 0.376\n",
            "690 에포크 정확도: 0.869\n",
            "691 에포크 loss: 0.381\n",
            "691 에포크 정확도: 0.864\n",
            "692 에포크 loss: 0.396\n",
            "692 에포크 정확도: 0.866\n",
            "693 에포크 loss: 0.380\n",
            "693 에포크 정확도: 0.866\n",
            "694 에포크 loss: 0.389\n",
            "694 에포크 정확도: 0.865\n",
            "695 에포크 loss: 0.383\n",
            "695 에포크 정확도: 0.871\n",
            "696 에포크 loss: 0.383\n",
            "696 에포크 정확도: 0.866\n",
            "697 에포크 loss: 0.377\n",
            "697 에포크 정확도: 0.866\n",
            "698 에포크 loss: 0.362\n",
            "698 에포크 정확도: 0.869\n",
            "699 에포크 loss: 0.377\n",
            "699 에포크 정확도: 0.867\n",
            "700 에포크 loss: 0.390\n",
            "700 에포크 정확도: 0.863\n",
            "701 에포크 loss: 0.400\n",
            "701 에포크 정확도: 0.859\n",
            "702 에포크 loss: 0.363\n",
            "702 에포크 정확도: 0.878\n",
            "703 에포크 loss: 0.352\n",
            "703 에포크 정확도: 0.871\n",
            "704 에포크 loss: 0.400\n",
            "704 에포크 정확도: 0.858\n",
            "705 에포크 loss: 0.395\n",
            "705 에포크 정확도: 0.863\n",
            "706 에포크 loss: 0.373\n",
            "706 에포크 정확도: 0.867\n",
            "707 에포크 loss: 0.380\n",
            "707 에포크 정확도: 0.865\n",
            "708 에포크 loss: 0.365\n",
            "708 에포크 정확도: 0.880\n",
            "709 에포크 loss: 0.385\n",
            "709 에포크 정확도: 0.865\n",
            "710 에포크 loss: 0.401\n",
            "710 에포크 정확도: 0.859\n",
            "711 에포크 loss: 0.410\n",
            "711 에포크 정확도: 0.848\n",
            "712 에포크 loss: 0.381\n",
            "712 에포크 정확도: 0.862\n",
            "713 에포크 loss: 0.412\n",
            "713 에포크 정확도: 0.859\n",
            "714 에포크 loss: 0.387\n",
            "714 에포크 정확도: 0.861\n",
            "715 에포크 loss: 0.382\n",
            "715 에포크 정확도: 0.864\n",
            "716 에포크 loss: 0.401\n",
            "716 에포크 정확도: 0.856\n",
            "717 에포크 loss: 0.375\n",
            "717 에포크 정확도: 0.867\n",
            "718 에포크 loss: 0.359\n",
            "718 에포크 정확도: 0.871\n",
            "719 에포크 loss: 0.403\n",
            "719 에포크 정확도: 0.853\n",
            "720 에포크 loss: 0.401\n",
            "720 에포크 정확도: 0.859\n",
            "721 에포크 loss: 0.386\n",
            "721 에포크 정확도: 0.865\n",
            "722 에포크 loss: 0.383\n",
            "722 에포크 정확도: 0.858\n",
            "723 에포크 loss: 0.400\n",
            "723 에포크 정확도: 0.854\n",
            "724 에포크 loss: 0.372\n",
            "724 에포크 정확도: 0.863\n",
            "725 에포크 loss: 0.362\n",
            "725 에포크 정확도: 0.875\n",
            "726 에포크 loss: 0.398\n",
            "726 에포크 정확도: 0.849\n",
            "727 에포크 loss: 0.370\n",
            "727 에포크 정확도: 0.869\n",
            "728 에포크 loss: 0.403\n",
            "728 에포크 정확도: 0.854\n",
            "729 에포크 loss: 0.376\n",
            "729 에포크 정확도: 0.875\n",
            "730 에포크 loss: 0.358\n",
            "730 에포크 정확도: 0.872\n",
            "731 에포크 loss: 0.375\n",
            "731 에포크 정확도: 0.866\n",
            "732 에포크 loss: 0.378\n",
            "732 에포크 정확도: 0.867\n",
            "733 에포크 loss: 0.391\n",
            "733 에포크 정확도: 0.866\n",
            "734 에포크 loss: 0.397\n",
            "734 에포크 정확도: 0.860\n",
            "735 에포크 loss: 0.376\n",
            "735 에포크 정확도: 0.871\n",
            "736 에포크 loss: 0.374\n",
            "736 에포크 정확도: 0.865\n",
            "737 에포크 loss: 0.359\n",
            "737 에포크 정확도: 0.874\n",
            "738 에포크 loss: 0.393\n",
            "738 에포크 정확도: 0.857\n",
            "739 에포크 loss: 0.361\n",
            "739 에포크 정확도: 0.873\n",
            "740 에포크 loss: 0.380\n",
            "740 에포크 정확도: 0.859\n",
            "741 에포크 loss: 0.360\n",
            "741 에포크 정확도: 0.872\n",
            "742 에포크 loss: 0.398\n",
            "742 에포크 정확도: 0.866\n",
            "743 에포크 loss: 0.415\n",
            "743 에포크 정확도: 0.848\n",
            "744 에포크 loss: 0.394\n",
            "744 에포크 정확도: 0.858\n",
            "745 에포크 loss: 0.343\n",
            "745 에포크 정확도: 0.870\n",
            "746 에포크 loss: 0.391\n",
            "746 에포크 정확도: 0.864\n",
            "747 에포크 loss: 0.391\n",
            "747 에포크 정확도: 0.869\n",
            "748 에포크 loss: 0.376\n",
            "748 에포크 정확도: 0.870\n",
            "749 에포크 loss: 0.384\n",
            "749 에포크 정확도: 0.859\n",
            "750 에포크 loss: 0.364\n",
            "750 에포크 정확도: 0.870\n",
            "751 에포크 loss: 0.372\n",
            "751 에포크 정확도: 0.876\n",
            "752 에포크 loss: 0.400\n",
            "752 에포크 정확도: 0.869\n",
            "753 에포크 loss: 0.388\n",
            "753 에포크 정확도: 0.867\n",
            "754 에포크 loss: 0.370\n",
            "754 에포크 정확도: 0.865\n",
            "755 에포크 loss: 0.374\n",
            "755 에포크 정확도: 0.871\n",
            "756 에포크 loss: 0.400\n",
            "756 에포크 정확도: 0.858\n",
            "757 에포크 loss: 0.378\n",
            "757 에포크 정확도: 0.867\n",
            "758 에포크 loss: 0.395\n",
            "758 에포크 정확도: 0.859\n",
            "759 에포크 loss: 0.381\n",
            "759 에포크 정확도: 0.869\n",
            "760 에포크 loss: 0.360\n",
            "760 에포크 정확도: 0.868\n",
            "761 에포크 loss: 0.366\n",
            "761 에포크 정확도: 0.878\n",
            "762 에포크 loss: 0.356\n",
            "762 에포크 정확도: 0.875\n",
            "763 에포크 loss: 0.391\n",
            "763 에포크 정확도: 0.863\n",
            "764 에포크 loss: 0.373\n",
            "764 에포크 정확도: 0.866\n",
            "765 에포크 loss: 0.380\n",
            "765 에포크 정확도: 0.865\n",
            "766 에포크 loss: 0.374\n",
            "766 에포크 정확도: 0.877\n",
            "767 에포크 loss: 0.407\n",
            "767 에포크 정확도: 0.861\n",
            "768 에포크 loss: 0.367\n",
            "768 에포크 정확도: 0.868\n",
            "769 에포크 loss: 0.368\n",
            "769 에포크 정확도: 0.869\n",
            "770 에포크 loss: 0.370\n",
            "770 에포크 정확도: 0.865\n",
            "771 에포크 loss: 0.347\n",
            "771 에포크 정확도: 0.873\n",
            "772 에포크 loss: 0.380\n",
            "772 에포크 정확도: 0.864\n",
            "773 에포크 loss: 0.375\n",
            "773 에포크 정확도: 0.868\n",
            "774 에포크 loss: 0.408\n",
            "774 에포크 정확도: 0.857\n",
            "775 에포크 loss: 0.384\n",
            "775 에포크 정확도: 0.859\n",
            "776 에포크 loss: 0.370\n",
            "776 에포크 정확도: 0.868\n",
            "777 에포크 loss: 0.384\n",
            "777 에포크 정확도: 0.855\n",
            "778 에포크 loss: 0.380\n",
            "778 에포크 정확도: 0.863\n",
            "779 에포크 loss: 0.404\n",
            "779 에포크 정확도: 0.861\n",
            "780 에포크 loss: 0.348\n",
            "780 에포크 정확도: 0.880\n",
            "781 에포크 loss: 0.394\n",
            "781 에포크 정확도: 0.861\n",
            "782 에포크 loss: 0.376\n",
            "782 에포크 정확도: 0.864\n",
            "783 에포크 loss: 0.365\n",
            "783 에포크 정확도: 0.876\n",
            "784 에포크 loss: 0.365\n",
            "784 에포크 정확도: 0.869\n",
            "785 에포크 loss: 0.395\n",
            "785 에포크 정확도: 0.864\n",
            "786 에포크 loss: 0.405\n",
            "786 에포크 정확도: 0.859\n",
            "787 에포크 loss: 0.371\n",
            "787 에포크 정확도: 0.862\n",
            "788 에포크 loss: 0.399\n",
            "788 에포크 정확도: 0.853\n",
            "789 에포크 loss: 0.357\n",
            "789 에포크 정확도: 0.869\n",
            "790 에포크 loss: 0.389\n",
            "790 에포크 정확도: 0.858\n",
            "791 에포크 loss: 0.386\n",
            "791 에포크 정확도: 0.866\n",
            "792 에포크 loss: 0.387\n",
            "792 에포크 정확도: 0.859\n",
            "793 에포크 loss: 0.403\n",
            "793 에포크 정확도: 0.860\n",
            "794 에포크 loss: 0.360\n",
            "794 에포크 정확도: 0.876\n",
            "795 에포크 loss: 0.381\n",
            "795 에포크 정확도: 0.876\n",
            "796 에포크 loss: 0.388\n",
            "796 에포크 정확도: 0.869\n",
            "797 에포크 loss: 0.385\n",
            "797 에포크 정확도: 0.866\n",
            "798 에포크 loss: 0.379\n",
            "798 에포크 정확도: 0.869\n",
            "799 에포크 loss: 0.356\n",
            "799 에포크 정확도: 0.873\n",
            "800 에포크 loss: 0.361\n",
            "800 에포크 정확도: 0.871\n",
            "801 에포크 loss: 0.380\n",
            "801 에포크 정확도: 0.863\n",
            "802 에포크 loss: 0.388\n",
            "802 에포크 정확도: 0.866\n",
            "803 에포크 loss: 0.356\n",
            "803 에포크 정확도: 0.881\n",
            "804 에포크 loss: 0.375\n",
            "804 에포크 정확도: 0.871\n",
            "805 에포크 loss: 0.386\n",
            "805 에포크 정확도: 0.857\n",
            "806 에포크 loss: 0.376\n",
            "806 에포크 정확도: 0.869\n",
            "807 에포크 loss: 0.361\n",
            "807 에포크 정확도: 0.866\n",
            "808 에포크 loss: 0.345\n",
            "808 에포크 정확도: 0.874\n",
            "809 에포크 loss: 0.349\n",
            "809 에포크 정확도: 0.877\n",
            "810 에포크 loss: 0.375\n",
            "810 에포크 정확도: 0.871\n",
            "811 에포크 loss: 0.390\n",
            "811 에포크 정확도: 0.866\n",
            "812 에포크 loss: 0.359\n",
            "812 에포크 정확도: 0.869\n",
            "813 에포크 loss: 0.391\n",
            "813 에포크 정확도: 0.861\n",
            "814 에포크 loss: 0.380\n",
            "814 에포크 정확도: 0.870\n",
            "815 에포크 loss: 0.405\n",
            "815 에포크 정확도: 0.855\n",
            "816 에포크 loss: 0.381\n",
            "816 에포크 정확도: 0.867\n",
            "817 에포크 loss: 0.374\n",
            "817 에포크 정확도: 0.865\n",
            "818 에포크 loss: 0.380\n",
            "818 에포크 정확도: 0.863\n",
            "819 에포크 loss: 0.388\n",
            "819 에포크 정확도: 0.869\n",
            "820 에포크 loss: 0.390\n",
            "820 에포크 정확도: 0.862\n",
            "821 에포크 loss: 0.358\n",
            "821 에포크 정확도: 0.871\n",
            "822 에포크 loss: 0.371\n",
            "822 에포크 정확도: 0.870\n",
            "823 에포크 loss: 0.370\n",
            "823 에포크 정확도: 0.875\n",
            "824 에포크 loss: 0.365\n",
            "824 에포크 정확도: 0.869\n",
            "825 에포크 loss: 0.373\n",
            "825 에포크 정확도: 0.858\n",
            "826 에포크 loss: 0.380\n",
            "826 에포크 정확도: 0.874\n",
            "827 에포크 loss: 0.370\n",
            "827 에포크 정확도: 0.865\n",
            "828 에포크 loss: 0.361\n",
            "828 에포크 정확도: 0.878\n",
            "829 에포크 loss: 0.377\n",
            "829 에포크 정확도: 0.869\n",
            "830 에포크 loss: 0.364\n",
            "830 에포크 정확도: 0.875\n",
            "831 에포크 loss: 0.363\n",
            "831 에포크 정확도: 0.872\n",
            "832 에포크 loss: 0.372\n",
            "832 에포크 정확도: 0.864\n",
            "833 에포크 loss: 0.380\n",
            "833 에포크 정확도: 0.868\n",
            "834 에포크 loss: 0.348\n",
            "834 에포크 정확도: 0.879\n",
            "835 에포크 loss: 0.375\n",
            "835 에포크 정확도: 0.866\n",
            "836 에포크 loss: 0.356\n",
            "836 에포크 정확도: 0.873\n",
            "837 에포크 loss: 0.388\n",
            "837 에포크 정확도: 0.865\n",
            "838 에포크 loss: 0.375\n",
            "838 에포크 정확도: 0.859\n",
            "839 에포크 loss: 0.389\n",
            "839 에포크 정확도: 0.863\n",
            "840 에포크 loss: 0.345\n",
            "840 에포크 정확도: 0.887\n",
            "841 에포크 loss: 0.353\n",
            "841 에포크 정확도: 0.877\n",
            "842 에포크 loss: 0.376\n",
            "842 에포크 정확도: 0.865\n",
            "843 에포크 loss: 0.396\n",
            "843 에포크 정확도: 0.862\n",
            "844 에포크 loss: 0.366\n",
            "844 에포크 정확도: 0.872\n",
            "845 에포크 loss: 0.378\n",
            "845 에포크 정확도: 0.869\n",
            "846 에포크 loss: 0.370\n",
            "846 에포크 정확도: 0.865\n",
            "847 에포크 loss: 0.365\n",
            "847 에포크 정확도: 0.866\n",
            "848 에포크 loss: 0.371\n",
            "848 에포크 정확도: 0.872\n",
            "849 에포크 loss: 0.361\n",
            "849 에포크 정확도: 0.878\n",
            "850 에포크 loss: 0.365\n",
            "850 에포크 정확도: 0.870\n",
            "851 에포크 loss: 0.391\n",
            "851 에포크 정확도: 0.869\n",
            "852 에포크 loss: 0.364\n",
            "852 에포크 정확도: 0.866\n",
            "853 에포크 loss: 0.362\n",
            "853 에포크 정확도: 0.878\n",
            "854 에포크 loss: 0.358\n",
            "854 에포크 정확도: 0.872\n",
            "855 에포크 loss: 0.378\n",
            "855 에포크 정확도: 0.873\n",
            "856 에포크 loss: 0.332\n",
            "856 에포크 정확도: 0.884\n",
            "857 에포크 loss: 0.370\n",
            "857 에포크 정확도: 0.871\n",
            "858 에포크 loss: 0.369\n",
            "858 에포크 정확도: 0.871\n",
            "859 에포크 loss: 0.396\n",
            "859 에포크 정확도: 0.864\n",
            "860 에포크 loss: 0.372\n",
            "860 에포크 정확도: 0.868\n",
            "861 에포크 loss: 0.365\n",
            "861 에포크 정확도: 0.872\n",
            "862 에포크 loss: 0.371\n",
            "862 에포크 정확도: 0.868\n",
            "863 에포크 loss: 0.386\n",
            "863 에포크 정확도: 0.861\n",
            "864 에포크 loss: 0.357\n",
            "864 에포크 정확도: 0.879\n",
            "865 에포크 loss: 0.360\n",
            "865 에포크 정확도: 0.874\n",
            "866 에포크 loss: 0.347\n",
            "866 에포크 정확도: 0.875\n",
            "867 에포크 loss: 0.361\n",
            "867 에포크 정확도: 0.878\n",
            "868 에포크 loss: 0.368\n",
            "868 에포크 정확도: 0.880\n",
            "869 에포크 loss: 0.375\n",
            "869 에포크 정확도: 0.861\n",
            "870 에포크 loss: 0.400\n",
            "870 에포크 정확도: 0.858\n",
            "871 에포크 loss: 0.389\n",
            "871 에포크 정확도: 0.860\n",
            "872 에포크 loss: 0.380\n",
            "872 에포크 정확도: 0.871\n",
            "873 에포크 loss: 0.364\n",
            "873 에포크 정확도: 0.876\n",
            "874 에포크 loss: 0.399\n",
            "874 에포크 정확도: 0.866\n",
            "875 에포크 loss: 0.367\n",
            "875 에포크 정확도: 0.867\n",
            "876 에포크 loss: 0.343\n",
            "876 에포크 정확도: 0.879\n",
            "877 에포크 loss: 0.370\n",
            "877 에포크 정확도: 0.867\n",
            "878 에포크 loss: 0.375\n",
            "878 에포크 정확도: 0.877\n",
            "879 에포크 loss: 0.391\n",
            "879 에포크 정확도: 0.868\n",
            "880 에포크 loss: 0.361\n",
            "880 에포크 정확도: 0.876\n",
            "881 에포크 loss: 0.368\n",
            "881 에포크 정확도: 0.861\n",
            "882 에포크 loss: 0.369\n",
            "882 에포크 정확도: 0.875\n",
            "883 에포크 loss: 0.358\n",
            "883 에포크 정확도: 0.872\n",
            "884 에포크 loss: 0.395\n",
            "884 에포크 정확도: 0.859\n",
            "885 에포크 loss: 0.367\n",
            "885 에포크 정확도: 0.871\n",
            "886 에포크 loss: 0.390\n",
            "886 에포크 정확도: 0.868\n",
            "887 에포크 loss: 0.372\n",
            "887 에포크 정확도: 0.875\n",
            "888 에포크 loss: 0.366\n",
            "888 에포크 정확도: 0.867\n",
            "889 에포크 loss: 0.366\n",
            "889 에포크 정확도: 0.875\n",
            "890 에포크 loss: 0.363\n",
            "890 에포크 정확도: 0.868\n",
            "891 에포크 loss: 0.387\n",
            "891 에포크 정확도: 0.853\n",
            "892 에포크 loss: 0.401\n",
            "892 에포크 정확도: 0.859\n",
            "893 에포크 loss: 0.395\n",
            "893 에포크 정확도: 0.850\n",
            "894 에포크 loss: 0.383\n",
            "894 에포크 정확도: 0.869\n",
            "895 에포크 loss: 0.383\n",
            "895 에포크 정확도: 0.860\n",
            "896 에포크 loss: 0.367\n",
            "896 에포크 정확도: 0.867\n",
            "897 에포크 loss: 0.388\n",
            "897 에포크 정확도: 0.860\n",
            "898 에포크 loss: 0.387\n",
            "898 에포크 정확도: 0.868\n",
            "899 에포크 loss: 0.359\n",
            "899 에포크 정확도: 0.878\n",
            "900 에포크 loss: 0.376\n",
            "900 에포크 정확도: 0.862\n",
            "901 에포크 loss: 0.349\n",
            "901 에포크 정확도: 0.885\n",
            "902 에포크 loss: 0.381\n",
            "902 에포크 정확도: 0.866\n",
            "903 에포크 loss: 0.363\n",
            "903 에포크 정확도: 0.872\n",
            "904 에포크 loss: 0.361\n",
            "904 에포크 정확도: 0.879\n",
            "905 에포크 loss: 0.371\n",
            "905 에포크 정확도: 0.863\n",
            "906 에포크 loss: 0.376\n",
            "906 에포크 정확도: 0.875\n",
            "907 에포크 loss: 0.363\n",
            "907 에포크 정확도: 0.872\n",
            "908 에포크 loss: 0.372\n",
            "908 에포크 정확도: 0.867\n",
            "909 에포크 loss: 0.378\n",
            "909 에포크 정확도: 0.866\n",
            "910 에포크 loss: 0.365\n",
            "910 에포크 정확도: 0.875\n",
            "911 에포크 loss: 0.381\n",
            "911 에포크 정확도: 0.867\n",
            "912 에포크 loss: 0.359\n",
            "912 에포크 정확도: 0.877\n",
            "913 에포크 loss: 0.393\n",
            "913 에포크 정확도: 0.866\n",
            "914 에포크 loss: 0.370\n",
            "914 에포크 정확도: 0.869\n",
            "915 에포크 loss: 0.356\n",
            "915 에포크 정확도: 0.875\n",
            "916 에포크 loss: 0.368\n",
            "916 에포크 정확도: 0.872\n",
            "917 에포크 loss: 0.366\n",
            "917 에포크 정확도: 0.879\n",
            "918 에포크 loss: 0.374\n",
            "918 에포크 정확도: 0.865\n",
            "919 에포크 loss: 0.335\n",
            "919 에포크 정확도: 0.869\n",
            "920 에포크 loss: 0.366\n",
            "920 에포크 정확도: 0.865\n",
            "921 에포크 loss: 0.357\n",
            "921 에포크 정확도: 0.871\n",
            "922 에포크 loss: 0.368\n",
            "922 에포크 정확도: 0.869\n",
            "923 에포크 loss: 0.347\n",
            "923 에포크 정확도: 0.881\n",
            "924 에포크 loss: 0.351\n",
            "924 에포크 정확도: 0.884\n",
            "925 에포크 loss: 0.366\n",
            "925 에포크 정확도: 0.871\n",
            "926 에포크 loss: 0.349\n",
            "926 에포크 정확도: 0.881\n",
            "927 에포크 loss: 0.396\n",
            "927 에포크 정확도: 0.864\n",
            "928 에포크 loss: 0.375\n",
            "928 에포크 정확도: 0.865\n",
            "929 에포크 loss: 0.386\n",
            "929 에포크 정확도: 0.863\n",
            "930 에포크 loss: 0.356\n",
            "930 에포크 정확도: 0.881\n",
            "931 에포크 loss: 0.332\n",
            "931 에포크 정확도: 0.885\n",
            "932 에포크 loss: 0.367\n",
            "932 에포크 정확도: 0.871\n",
            "933 에포크 loss: 0.345\n",
            "933 에포크 정확도: 0.877\n",
            "934 에포크 loss: 0.411\n",
            "934 에포크 정확도: 0.845\n",
            "935 에포크 loss: 0.335\n",
            "935 에포크 정확도: 0.880\n",
            "936 에포크 loss: 0.357\n",
            "936 에포크 정확도: 0.875\n",
            "937 에포크 loss: 0.341\n",
            "937 에포크 정확도: 0.875\n",
            "938 에포크 loss: 0.365\n",
            "938 에포크 정확도: 0.875\n",
            "939 에포크 loss: 0.377\n",
            "939 에포크 정확도: 0.867\n",
            "940 에포크 loss: 0.385\n",
            "940 에포크 정확도: 0.860\n",
            "941 에포크 loss: 0.355\n",
            "941 에포크 정확도: 0.872\n",
            "942 에포크 loss: 0.390\n",
            "942 에포크 정확도: 0.857\n",
            "943 에포크 loss: 0.373\n",
            "943 에포크 정확도: 0.869\n",
            "944 에포크 loss: 0.364\n",
            "944 에포크 정확도: 0.877\n",
            "945 에포크 loss: 0.388\n",
            "945 에포크 정확도: 0.857\n",
            "946 에포크 loss: 0.377\n",
            "946 에포크 정확도: 0.868\n",
            "947 에포크 loss: 0.383\n",
            "947 에포크 정확도: 0.870\n",
            "948 에포크 loss: 0.360\n",
            "948 에포크 정확도: 0.868\n",
            "949 에포크 loss: 0.340\n",
            "949 에포크 정확도: 0.877\n",
            "950 에포크 loss: 0.401\n",
            "950 에포크 정확도: 0.857\n",
            "951 에포크 loss: 0.376\n",
            "951 에포크 정확도: 0.861\n",
            "952 에포크 loss: 0.380\n",
            "952 에포크 정확도: 0.866\n",
            "953 에포크 loss: 0.380\n",
            "953 에포크 정확도: 0.860\n",
            "954 에포크 loss: 0.347\n",
            "954 에포크 정확도: 0.892\n",
            "955 에포크 loss: 0.374\n",
            "955 에포크 정확도: 0.872\n",
            "956 에포크 loss: 0.361\n",
            "956 에포크 정확도: 0.868\n",
            "957 에포크 loss: 0.378\n",
            "957 에포크 정확도: 0.870\n",
            "958 에포크 loss: 0.377\n",
            "958 에포크 정확도: 0.869\n",
            "959 에포크 loss: 0.381\n",
            "959 에포크 정확도: 0.866\n",
            "960 에포크 loss: 0.376\n",
            "960 에포크 정확도: 0.869\n",
            "961 에포크 loss: 0.391\n",
            "961 에포크 정확도: 0.860\n",
            "962 에포크 loss: 0.382\n",
            "962 에포크 정확도: 0.863\n",
            "963 에포크 loss: 0.335\n",
            "963 에포크 정확도: 0.880\n",
            "964 에포크 loss: 0.367\n",
            "964 에포크 정확도: 0.871\n",
            "965 에포크 loss: 0.380\n",
            "965 에포크 정확도: 0.869\n",
            "966 에포크 loss: 0.367\n",
            "966 에포크 정확도: 0.873\n",
            "967 에포크 loss: 0.351\n",
            "967 에포크 정확도: 0.879\n",
            "968 에포크 loss: 0.375\n",
            "968 에포크 정확도: 0.884\n",
            "969 에포크 loss: 0.371\n",
            "969 에포크 정확도: 0.868\n",
            "970 에포크 loss: 0.374\n",
            "970 에포크 정확도: 0.879\n",
            "971 에포크 loss: 0.374\n",
            "971 에포크 정확도: 0.867\n",
            "972 에포크 loss: 0.341\n",
            "972 에포크 정확도: 0.878\n",
            "973 에포크 loss: 0.393\n",
            "973 에포크 정확도: 0.863\n",
            "974 에포크 loss: 0.362\n",
            "974 에포크 정확도: 0.876\n",
            "975 에포크 loss: 0.364\n",
            "975 에포크 정확도: 0.874\n",
            "976 에포크 loss: 0.351\n",
            "976 에포크 정확도: 0.879\n",
            "977 에포크 loss: 0.367\n",
            "977 에포크 정확도: 0.865\n",
            "978 에포크 loss: 0.388\n",
            "978 에포크 정확도: 0.863\n",
            "979 에포크 loss: 0.382\n",
            "979 에포크 정확도: 0.871\n",
            "980 에포크 loss: 0.391\n",
            "980 에포크 정확도: 0.863\n",
            "981 에포크 loss: 0.381\n",
            "981 에포크 정확도: 0.867\n",
            "982 에포크 loss: 0.370\n",
            "982 에포크 정확도: 0.876\n",
            "983 에포크 loss: 0.373\n",
            "983 에포크 정확도: 0.863\n",
            "984 에포크 loss: 0.351\n",
            "984 에포크 정확도: 0.874\n",
            "985 에포크 loss: 0.355\n",
            "985 에포크 정확도: 0.875\n",
            "986 에포크 loss: 0.338\n",
            "986 에포크 정확도: 0.878\n",
            "987 에포크 loss: 0.362\n",
            "987 에포크 정확도: 0.872\n",
            "988 에포크 loss: 0.357\n",
            "988 에포크 정확도: 0.876\n",
            "989 에포크 loss: 0.363\n",
            "989 에포크 정확도: 0.872\n",
            "990 에포크 loss: 0.373\n",
            "990 에포크 정확도: 0.865\n",
            "991 에포크 loss: 0.371\n",
            "991 에포크 정확도: 0.863\n",
            "992 에포크 loss: 0.395\n",
            "992 에포크 정확도: 0.866\n",
            "993 에포크 loss: 0.362\n",
            "993 에포크 정확도: 0.873\n",
            "994 에포크 loss: 0.375\n",
            "994 에포크 정확도: 0.868\n",
            "995 에포크 loss: 0.354\n",
            "995 에포크 정확도: 0.873\n",
            "996 에포크 loss: 0.362\n",
            "996 에포크 정확도: 0.875\n",
            "997 에포크 loss: 0.361\n",
            "997 에포크 정확도: 0.872\n",
            "998 에포크 loss: 0.399\n",
            "998 에포크 정확도: 0.869\n",
            "999 에포크 loss: 0.357\n",
            "999 에포크 정확도: 0.869\n",
            "1000 에포크 loss: 0.360\n",
            "1000 에포크 정확도: 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # 모델을 평가모드로 바꿉니다. dropout이 일어나지 않습니다.\n",
        "\n",
        "with torch.no_grad(): # 이 안의 코드는 가중치 업데이트가 일어나지 않습니다.\n",
        "    outputs = model(test_x)\n",
        "    _, pred = torch.max(outputs, 1)\n",
        "\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96K4OdJmV9l3",
        "outputId": "03178d52-c477-492c-9106-a0c75d10d111"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1,  ..., 2, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission['target'] = pred.numpy()\n",
        "sample_submission['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L0-CIcIWDkI",
        "outputId": "e08b871a-a76a-45cb-8abd-d54911e555b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    3203\n",
              "2    2332\n",
              "0    1917\n",
              "3    1891\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.to_csv('result_submission.csv',index=False)"
      ],
      "metadata": {
        "id": "vKXJcJraWE4D"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}